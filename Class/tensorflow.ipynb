{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning ( TensorFlow )\n",
    "* https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netural Network\n",
    "- features(x) -> neuron -> target(y)\n",
    "    - ex) 주택 가격  \n",
    "    features(크기, 위치, 형태, ..) -> neuron(가중치, 그래프, 관계) -> target(가격)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]),\n",
       " array([-1,  1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31,\n",
       "        33, 35, 37]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(range(0,20))\n",
    "y = x * 2 - 1\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20,), (20,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kears 모델 클리어\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# keras 모델 선언\n",
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 노드 조립\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# 컴파일\n",
    "# loss : 예측값 평가 기준 \n",
    "# optimizer : \n",
    "model.compile(loss='mse'\n",
    "              , optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 1372.7797\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1371.8937\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1371.0076\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1370.1223\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1369.2371\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1368.3522\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1367.4677\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1366.5833\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1365.6995\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1364.8159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216a3b06d90>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs : 학습 횟수\n",
    "# verbose : 학습 과정 표현\n",
    "model.fit(x,y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.99897718e-03],\n",
       "       [-1.39060831e+00],\n",
       "       [-2.79121566e+00],\n",
       "       [-4.19182348e+00],\n",
       "       [-5.59243059e+00],\n",
       "       [-6.99303770e+00],\n",
       "       [-8.39364529e+00],\n",
       "       [-9.79425240e+00],\n",
       "       [-1.11948595e+01],\n",
       "       [-1.25954666e+01],\n",
       "       [-1.39960737e+01],\n",
       "       [-1.53966818e+01],\n",
       "       [-1.67972908e+01],\n",
       "       [-1.81978970e+01],\n",
       "       [-1.95985050e+01],\n",
       "       [-2.09991112e+01],\n",
       "       [-2.23997192e+01],\n",
       "       [-2.38003273e+01],\n",
       "       [-2.52009335e+01],\n",
       "       [-2.66015415e+01]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(range(0,40)) \n",
    "y = np.array([0, 1] * 20)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              , optimizer='adam'\n",
    "              , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 6.2067 - accuracy: 0.5250\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.1862 - accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.1677 - accuracy: 0.5250\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.1491 - accuracy: 0.5250\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.1315 - accuracy: 0.5250\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.1124 - accuracy: 0.5250\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.0935 - accuracy: 0.5250\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0760 - accuracy: 0.5250\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0559 - accuracy: 0.5250\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.0384 - accuracy: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216a3c888b0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49519983],\n",
       "       [0.64821047],\n",
       "       [0.7758364 ],\n",
       "       [0.86668366],\n",
       "       [0.92430526],\n",
       "       [0.9582222 ],\n",
       "       [0.97731483],\n",
       "       [0.98779327],\n",
       "       [0.99346393],\n",
       "       [0.9965096 ],\n",
       "       [0.99813867],\n",
       "       [0.99900824],\n",
       "       [0.9994717 ],\n",
       "       [0.9997187 ],\n",
       "       [0.99985015],\n",
       "       [0.99992025],\n",
       "       [0.99995756],\n",
       "       [0.99997735],\n",
       "       [0.99998796],\n",
       "       [0.99999356],\n",
       "       [0.99999654],\n",
       "       [0.9999982 ],\n",
       "       [0.99999905],\n",
       "       [0.9999995 ],\n",
       "       [0.99999976],\n",
       "       [0.9999999 ],\n",
       "       [0.9999999 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[-1  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = x * 2 -1\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 267.5563\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 267.1657\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 266.7753\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 266.3853\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 265.9955\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 265.6061\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 265.2169\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 264.8282\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 264.4397\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 264.0515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216a3b13250>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "[0.00999757 0.47192705 0.9338565  1.395786   1.8577155  2.319645\n",
      " 2.7815745  3.2435038  3.7054334  4.1673627  4.629292   5.0912213\n",
      " 5.553151   6.0150805  6.47701    6.9389396  7.400869   7.862798\n",
      " 8.324728   8.786657  ]\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 1.7962 - accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7936 - accuracy: 0.5500\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7910 - accuracy: 0.5500\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7884 - accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7857 - accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7831 - accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7805 - accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7779 - accuracy: 0.5500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7752 - accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7726 - accuracy: 0.5500\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "WARNING:tensorflow:5 out of the last 318 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000216A505F820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "[0.4975002  0.6783181  0.8178883  0.90535194 0.953212   0.97747314\n",
      " 0.9892953  0.99494535 0.9976203  0.9988813  0.99947447 0.9997532\n",
      " 0.9998841  0.9999455  0.9999745  0.99998796 0.9999944  0.9999974\n",
      " 0.9999988  0.9999994 ]\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "\n",
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN / MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = 1651\n",
      "다음 그림은 숫자 3 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "# id = 0\n",
    "\n",
    "print(f'id = {id}')\n",
    "print(f'다음 그림은 숫자 {y_train[id]} 입니다.')\n",
    "\n",
    "plt.imshow(x_train[id])\n",
    "plt.show()\n",
    "\n",
    "# print(x_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0], x_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3차원 -> 2차원\n",
    "x_train = x_train.reshape([x_train.shape[0],-1])\n",
    "x_val = x_val.reshape([x_val.shape[0],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max : 255 / min : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'max : {x_train.max()} / min : {x_train.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_n, min_n = x_train.max(), x_train.min()\n",
    "\n",
    "max_n, min_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train[0] - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - min_n) / (max_n - min_n)\n",
    "x_val = (x_val - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Sequential API\n",
    "# # 1. 세션 클리어\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# # 2. 모델 선언 : Sequential()\n",
    "# model = keras.models.Sequential()\n",
    "\n",
    "# # 3. 레이어 조립 : .add()\n",
    "# model.add( keras.layers.Input(shape=(784,)) )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add( keras.layers.Dense(10, activation='softmax') )\n",
    "\n",
    "# # 4. 컴파일\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "#               optimizer=keras.optimizers.Adam(0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functional API\n",
    "# 1. 세션 클리어\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 2. 레이어 사슬처럼 엮기\n",
    "il = keras.layers.Input(shape=(784,))\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "ol = keras.layers.Dense(10, activation='softmax')(il)\n",
    "\n",
    "# 3. 모델의 시작과 끝 지정\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "# 4. 컴파일\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', # 관측 대상\n",
    "                   min_delta=0,        # 최소한 나빠지지 않으면 괜찮아\n",
    "                   patience=5,         # 성능 개선되지 않는 걸 얼마나 참을래?\n",
    "                   verbose=1,\n",
    "                   restore_best_weights=True # 학습이 멈췄을 때, 최적의 가중치로 전환해줌\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3795 - accuracy: 0.8926 - val_loss: 0.3292 - val_accuracy: 0.9122\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3348 - accuracy: 0.9095 - val_loss: 0.3781 - val_accuracy: 0.9008\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3346 - accuracy: 0.9116 - val_loss: 0.3517 - val_accuracy: 0.9083\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3284 - accuracy: 0.9112 - val_loss: 0.3233 - val_accuracy: 0.9187\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3232 - accuracy: 0.9139 - val_loss: 0.3339 - val_accuracy: 0.9168\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3241 - accuracy: 0.9144 - val_loss: 0.3580 - val_accuracy: 0.9054\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3233 - accuracy: 0.9141 - val_loss: 0.3427 - val_accuracy: 0.9190\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3138 - accuracy: 0.9176 - val_loss: 0.3506 - val_accuracy: 0.9128\n",
      "Epoch 9/50\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.9164Restoring model weights from the end of the best epoch: 4.\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3187 - accuracy: 0.9163 - val_loss: 0.3397 - val_accuracy: 0.9202\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2167dd0b730>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, verbose=1,\n",
    "          validation_split=0.2,    # Train data의 20%를 Validation data로!\n",
    "          callbacks=[es]           # Early Stopping 적용\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "pred_val = model.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train.shape, pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_val = pred_val.argmax(axis=1)\n",
    "single_pred_train.shape, single_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9233"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_train_accuracy = accuracy_score(y_train.argmax(axis=1), single_pred_train)\n",
    "logi_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_test_accuracy = accuracy_score(y_val.argmax(axis=1), single_pred_val)\n",
    "logi_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i, index in enumerate(np.random.choice(x_val.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1)\n",
    "    # Display each image\n",
    "    ax.imshow(x_val[index].reshape([28,-1]), cmap='gray' )\n",
    "    \n",
    "    predict_index = pred_val[index].argmax(axis=0)\n",
    "    true_index = y_val[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(f\"{mnist_labels[predict_index]} ({mnist_labels[true_index]})\",\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3316 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3316243290901184, 0.9211000204086304]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) 3차원 array 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.array(\n",
    "    [\n",
    "        [\n",
    "                       [0, 0],\n",
    "                       [2,-1],\n",
    "                       [1, 0],\n",
    "                       [2, 2],\n",
    "        ],\n",
    "        [\n",
    "                       [1, 1],\n",
    "                       [3, 3],\n",
    "                       [2,-1],\n",
    "                       [1, 1],\n",
    "        ],\n",
    "        [\n",
    "                       [2, 2],\n",
    "                       [7,-1],\n",
    "                       [8, 1],\n",
    "                       [1, 0],\n",
    "        ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample   = n1.shape[0] # 3 (3개 샘플 데이터)\n",
    "num_sequence = n1.shape[1] # 4 (4개 시계열 데이터)\n",
    "num_feature  = n1.shape[2] # 2 (2개 Feature(미세먼지, 초미세먼지 증감))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss 0\n",
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]]\n",
      "\n",
      "ss 1\n",
      "[[ 2 -1]\n",
      " [ 3  3]\n",
      " [ 7 -1]]\n",
      "\n",
      "ss 2\n",
      "[[ 1  0]\n",
      " [ 2 -1]\n",
      " [ 8  1]]\n",
      "\n",
      "ss 3\n",
      "[[2 2]\n",
      " [1 1]\n",
      " [1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 시계열을 선회하면서 피팅합니다\n",
    "for ss in range(num_sequence):\n",
    "    print('ss', ss)\n",
    "    print(n1[:, ss, :])\n",
    "    print()\n",
    "    scaler.partial_fit(n1[:, ss, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.   , 0.25 ]],\n",
      "\n",
      "       [[0.125, 0.5  ]],\n",
      "\n",
      "       [[0.25 , 0.75 ]]]), array([[[0.25 , 0.   ]],\n",
      "\n",
      "       [[0.375, 1.   ]],\n",
      "\n",
      "       [[0.875, 0.   ]]]), array([[[0.125, 0.25 ]],\n",
      "\n",
      "       [[0.25 , 0.   ]],\n",
      "\n",
      "       [[1.   , 0.5  ]]]), array([[[0.25 , 0.75 ]],\n",
      "\n",
      "       [[0.125, 0.5  ]],\n",
      "\n",
      "       [[0.125, 0.25 ]]])]\n",
      "\n",
      "[[[0.    0.25 ]\n",
      "  [0.25  0.   ]\n",
      "  [0.125 0.25 ]\n",
      "  [0.25  0.75 ]]\n",
      "\n",
      " [[0.125 0.5  ]\n",
      "  [0.375 1.   ]\n",
      "  [0.25  0.   ]\n",
      "  [0.125 0.5  ]]\n",
      "\n",
      " [[0.25  0.75 ]\n",
      "  [0.875 0.   ]\n",
      "  [1.    0.5  ]\n",
      "  [0.125 0.25 ]]]\n"
     ]
    }
   ],
   "source": [
    "# 스케일링(변환)합니다.\n",
    "results = []\n",
    "for ss in range(num_sequence):\n",
    "    results.append(scaler.transform(n1[:, ss, :]).reshape(num_sample, 1, num_feature))\n",
    "\n",
    "print(results)\n",
    "print()\n",
    "\n",
    "n1_scaled = np.concatenate(results, axis=1)\n",
    "print(n1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) tensorflow GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://afsdzvcx123.tistory.com/entry/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-Windows%EC%9C%88%EB%8F%84%EC%9A%B0-CUDA-cuDNN-%EC%84%A4%EC%B9%98%EB%B0%A9%EB%B2%95\n",
    "* https://doitgrow.com/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8382490936418313836\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254700544\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2544310863419836720\n",
      "physical_device_desc: \"device: 0, name: Quadro T1000 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# GPU 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gpu 사용\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cpu 사용\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Airplane', 1: 'Automobile', 2: 'Bird', 3: 'Cat', 4: 'Deer', 5: 'Dog', 6: 'Frog', 7: 'Horse', 8: 'Ship', 9: 'Truck'}\n"
     ]
    }
   ],
   "source": [
    "labels = { 0 : 'Airplane',\n",
    "          1 : 'Automobile',\n",
    "          2 : 'Bird',\n",
    "          3 : 'Cat',\n",
    "          4 : 'Deer',\n",
    "          5 : 'Dog',\n",
    "          6 : 'Frog',\n",
    "          7 : 'Horse',\n",
    "          8 : 'Ship',\n",
    "          9 : 'Truck' }\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = 2785\n",
      "다음 그림은 Deer 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "\n",
    "print('id = {}'.format(id))\n",
    "print('다음 그림은 {} 입니다.'.format( labels[test_y[id][0]] ))\n",
    "plt.imshow(test_x[id])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n, min_n = train_x.max(), train_x.min()\n",
    "\n",
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_n = len(np.unique(train_y))\n",
    "class_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, class_n)\n",
    "test_y = to_categorical(test_y, class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 10), (10000, 10))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 521)               1601033   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 521)               271962    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               66816     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,941,101\n",
      "Trainable params: 1,941,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(32,32,3))\n",
    "fl = keras.layers.Flatten()(il)\n",
    "hl = keras.layers.Dense(521, activation='relu')(fl)\n",
    "hl = keras.layers.Dense(521, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(128, activation='relu')(hl)\n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = keras.callbacks.EarlyStopping(verbose=1\n",
    "                                    , patience=5\n",
    "                                    , restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 1.8846 - accuracy: 0.3140 - val_loss: 1.8252 - val_accuracy: 0.3449\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6989 - accuracy: 0.3884 - val_loss: 1.7219 - val_accuracy: 0.3796\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6235 - accuracy: 0.4154 - val_loss: 1.6354 - val_accuracy: 0.4104\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5661 - accuracy: 0.4388 - val_loss: 1.6033 - val_accuracy: 0.4274\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5217 - accuracy: 0.4543 - val_loss: 1.5418 - val_accuracy: 0.4436\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4834 - accuracy: 0.4666 - val_loss: 1.5232 - val_accuracy: 0.4583\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4513 - accuracy: 0.4792 - val_loss: 1.6105 - val_accuracy: 0.4352\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4288 - accuracy: 0.4864 - val_loss: 1.5151 - val_accuracy: 0.4671\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.3977 - accuracy: 0.4970 - val_loss: 1.5238 - val_accuracy: 0.4638\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3821 - accuracy: 0.5039 - val_loss: 1.5140 - val_accuracy: 0.4650\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.3562 - accuracy: 0.5141 - val_loss: 1.4937 - val_accuracy: 0.4768\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3298 - accuracy: 0.5192 - val_loss: 1.5272 - val_accuracy: 0.4637\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.3099 - accuracy: 0.5297 - val_loss: 1.4717 - val_accuracy: 0.4804\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.2893 - accuracy: 0.5354 - val_loss: 1.4681 - val_accuracy: 0.4844\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2670 - accuracy: 0.5434 - val_loss: 1.4631 - val_accuracy: 0.4902\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2523 - accuracy: 0.5481 - val_loss: 1.5155 - val_accuracy: 0.4793\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2292 - accuracy: 0.5582 - val_loss: 1.5100 - val_accuracy: 0.4786\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2091 - accuracy: 0.5615 - val_loss: 1.5140 - val_accuracy: 0.4855\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.1927 - accuracy: 0.5671 - val_loss: 1.5272 - val_accuracy: 0.4781\n",
      "Epoch 20/50\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.1715 - accuracy: 0.5762Restoring model weights from the end of the best epoch: 15.\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1712 - accuracy: 0.5764 - val_loss: 1.5491 - val_accuracy: 0.4783\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, callbacks=[call],\n",
    "                    epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4435 - accuracy: 0.4904\n",
      "Test Loss : 1.443493,  Test Accuracy : 49.040%\n"
     ]
    }
   ],
   "source": [
    "performance_test = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not isinstance(history, dict):\n",
    "    history = history.history\n",
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "\n",
    "plt.title('Training vs Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(history.keys(), loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "트레이닝 정확도 : 56.08%\n",
      "테스트 정확도 : 49.04%\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(train_x)\n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_test = pred_test.argmax(axis=1)\n",
    "\n",
    "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
    "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
    "\n",
    "\n",
    "print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))\n",
    "print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = 1329\n",
      "다음 그림은 Dog 입니다.\n",
      "모델의 예측 : Bird\n",
      "모델의 카테고리별 확률 : \n",
      "{'Airplane': 4.0, 'Automobile': 0.0, 'Bird': 28.0, 'Cat': 9.0, 'Deer': 15.0, 'Dog': 14.0, 'Frog': 16.0, 'Horse': 10.0, 'Ship': 0.0, 'Truck': 1.0}\n",
      "틀렸어요\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "\n",
    "print('id = {}'.format(id))\n",
    "print('다음 그림은 {} 입니다.'.format(labels[test_y.argmax(axis=1)[id]] ))\n",
    "print('모델의 예측 : {}'.format(labels[single_pred_test[id]] ))\n",
    "\n",
    "prob = np.floor(pred_test[id]*100).tolist()\n",
    "prob_dict = {}\n",
    "\n",
    "for idx, prob in enumerate(prob) :\n",
    "    prob_dict[ labels[idx] ] = prob\n",
    "\n",
    "print('모델의 카테고리별 확률 : ')\n",
    "print(prob_dict)\n",
    "\n",
    "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
    "    print('정답입니다')\n",
    "else : \n",
    "    print('틀렸어요')\n",
    "    \n",
    "plt.imshow(test_x[id].reshape([32,32,-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(x, columns=iris.feature_names)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135, 4), (15, 4), (135,), (15,))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_l = x_train[['sepal length (cm)', 'petal length (cm)']]\n",
    "x_train_w = x_train[['sepal width (cm)', 'petal width (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_l = x_val[['sepal length (cm)', 'petal length (cm)']]\n",
    "x_val_w = x_val[['sepal width (cm)', 'petal width (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_y = len(set(y))\n",
    "len_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, len_y)\n",
    "y_val = to_categorical(y_val, len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135, 4), (15, 4), (135, 3), (15, 3))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            6           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            6           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4)            0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            15          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il_l = keras.layers.Input(shape=(2,))\n",
    "hl_l = keras.layers.Dense(2, activation='relu')(il_l)\n",
    "\n",
    "il_w = keras.layers.Input(shape=(2,))\n",
    "hl_w = keras.layers.Dense(2, activation='relu')(il_w)\n",
    "\n",
    "# 2개의 Input 연결\n",
    "cl = keras.layers.Concatenate()([hl_l, hl_w])\n",
    "ol = keras.layers.Dense(3, activation='softmax')(cl)\n",
    "\n",
    "model = keras.models.Model([il_l, il_w], ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5,\n",
    "                                    verbose=1,\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 1.6106 - accuracy: 0.3636 - val_loss: 1.4019 - val_accuracy: 0.2857\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5741 - accuracy: 0.3636 - val_loss: 1.3763 - val_accuracy: 0.2857\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5377 - accuracy: 0.3636 - val_loss: 1.3506 - val_accuracy: 0.2857\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5050 - accuracy: 0.3636 - val_loss: 1.3263 - val_accuracy: 0.2857\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.4752 - accuracy: 0.3636 - val_loss: 1.3050 - val_accuracy: 0.2857\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.4447 - accuracy: 0.3636 - val_loss: 1.2868 - val_accuracy: 0.2857\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.4173 - accuracy: 0.3636 - val_loss: 1.2688 - val_accuracy: 0.2857\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3924 - accuracy: 0.3636 - val_loss: 1.2530 - val_accuracy: 0.2857\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3679 - accuracy: 0.3636 - val_loss: 1.2382 - val_accuracy: 0.2857\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3461 - accuracy: 0.3636 - val_loss: 1.2250 - val_accuracy: 0.2857\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.3224 - accuracy: 0.3636 - val_loss: 1.2116 - val_accuracy: 0.2857\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3030 - accuracy: 0.3636 - val_loss: 1.2003 - val_accuracy: 0.2857\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2810 - accuracy: 0.3636 - val_loss: 1.1893 - val_accuracy: 0.2857\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2627 - accuracy: 0.3636 - val_loss: 1.1793 - val_accuracy: 0.2857\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2457 - accuracy: 0.3636 - val_loss: 1.1705 - val_accuracy: 0.2857\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2272 - accuracy: 0.3636 - val_loss: 1.1629 - val_accuracy: 0.2857\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2128 - accuracy: 0.3636 - val_loss: 1.1552 - val_accuracy: 0.2857\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1975 - accuracy: 0.3636 - val_loss: 1.1485 - val_accuracy: 0.2857\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1830 - accuracy: 0.3636 - val_loss: 1.1435 - val_accuracy: 0.2857\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1702 - accuracy: 0.3636 - val_loss: 1.1397 - val_accuracy: 0.2857\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1587 - accuracy: 0.3636 - val_loss: 1.1359 - val_accuracy: 0.2857\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1478 - accuracy: 0.3636 - val_loss: 1.1334 - val_accuracy: 0.2857\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1387 - accuracy: 0.3636 - val_loss: 1.1305 - val_accuracy: 0.2857\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1309 - accuracy: 0.3636 - val_loss: 1.1279 - val_accuracy: 0.2857\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1228 - accuracy: 0.3636 - val_loss: 1.1263 - val_accuracy: 0.2857\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1151 - accuracy: 0.3636 - val_loss: 1.1247 - val_accuracy: 0.2857\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1089 - accuracy: 0.3719 - val_loss: 1.1231 - val_accuracy: 0.2857\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1041 - accuracy: 0.3884 - val_loss: 1.1228 - val_accuracy: 0.3571\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1007 - accuracy: 0.4132 - val_loss: 1.1232 - val_accuracy: 0.2857\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0950 - accuracy: 0.4380 - val_loss: 1.1220 - val_accuracy: 0.2857\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0924 - accuracy: 0.4545 - val_loss: 1.1214 - val_accuracy: 0.2857\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0882 - accuracy: 0.4711 - val_loss: 1.1215 - val_accuracy: 0.2857\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0865 - accuracy: 0.5041 - val_loss: 1.1205 - val_accuracy: 0.2857\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0839 - accuracy: 0.5372 - val_loss: 1.1203 - val_accuracy: 0.2857\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0810 - accuracy: 0.5455 - val_loss: 1.1199 - val_accuracy: 0.2857\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0793 - accuracy: 0.5785 - val_loss: 1.1191 - val_accuracy: 0.3571\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0774 - accuracy: 0.6033 - val_loss: 1.1183 - val_accuracy: 0.3571\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0757 - accuracy: 0.6198 - val_loss: 1.1175 - val_accuracy: 0.3571\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0743 - accuracy: 0.6198 - val_loss: 1.1154 - val_accuracy: 0.3571\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0731 - accuracy: 0.5950 - val_loss: 1.1136 - val_accuracy: 0.4286\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0713 - accuracy: 0.6116 - val_loss: 1.1134 - val_accuracy: 0.4286\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0699 - accuracy: 0.6033 - val_loss: 1.1129 - val_accuracy: 0.4286\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0690 - accuracy: 0.5537 - val_loss: 1.1108 - val_accuracy: 0.2857\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0677 - accuracy: 0.4463 - val_loss: 1.1112 - val_accuracy: 0.2143\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0661 - accuracy: 0.4132 - val_loss: 1.1108 - val_accuracy: 0.2143\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0648 - accuracy: 0.4050 - val_loss: 1.1097 - val_accuracy: 0.2143\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0636 - accuracy: 0.3719 - val_loss: 1.1084 - val_accuracy: 0.2143\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0623 - accuracy: 0.3388 - val_loss: 1.1085 - val_accuracy: 0.2143\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0610 - accuracy: 0.3967 - val_loss: 1.1074 - val_accuracy: 0.2143\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0598 - accuracy: 0.3636 - val_loss: 1.1061 - val_accuracy: 0.2143\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0586 - accuracy: 0.3554 - val_loss: 1.1060 - val_accuracy: 0.2143\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0571 - accuracy: 0.3554 - val_loss: 1.1052 - val_accuracy: 0.2143\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0559 - accuracy: 0.3884 - val_loss: 1.1048 - val_accuracy: 0.2143\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0545 - accuracy: 0.4215 - val_loss: 1.1032 - val_accuracy: 0.2143\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0531 - accuracy: 0.3967 - val_loss: 1.1026 - val_accuracy: 0.2143\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0518 - accuracy: 0.4380 - val_loss: 1.1023 - val_accuracy: 0.2857\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0504 - accuracy: 0.4545 - val_loss: 1.1004 - val_accuracy: 0.2143\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0490 - accuracy: 0.3884 - val_loss: 1.0986 - val_accuracy: 0.2143\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0477 - accuracy: 0.3636 - val_loss: 1.0972 - val_accuracy: 0.2143\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0461 - accuracy: 0.3636 - val_loss: 1.0977 - val_accuracy: 0.2143\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0447 - accuracy: 0.4215 - val_loss: 1.0976 - val_accuracy: 0.2857\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0431 - accuracy: 0.4876 - val_loss: 1.0972 - val_accuracy: 0.2857\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0418 - accuracy: 0.5455 - val_loss: 1.0963 - val_accuracy: 0.2857\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0404 - accuracy: 0.6033 - val_loss: 1.0963 - val_accuracy: 0.3571\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0389 - accuracy: 0.6281 - val_loss: 1.0948 - val_accuracy: 0.4286\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0372 - accuracy: 0.6281 - val_loss: 1.0937 - val_accuracy: 0.4286\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0357 - accuracy: 0.6529 - val_loss: 1.0929 - val_accuracy: 0.4286\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0341 - accuracy: 0.6446 - val_loss: 1.0917 - val_accuracy: 0.4286\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0328 - accuracy: 0.6612 - val_loss: 1.0907 - val_accuracy: 0.4286\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0310 - accuracy: 0.6694 - val_loss: 1.0885 - val_accuracy: 0.4286\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0294 - accuracy: 0.6694 - val_loss: 1.0868 - val_accuracy: 0.4286\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0279 - accuracy: 0.6529 - val_loss: 1.0847 - val_accuracy: 0.4286\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0261 - accuracy: 0.6612 - val_loss: 1.0841 - val_accuracy: 0.4286\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0245 - accuracy: 0.6860 - val_loss: 1.0832 - val_accuracy: 0.4286\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0230 - accuracy: 0.6860 - val_loss: 1.0832 - val_accuracy: 0.4286\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0213 - accuracy: 0.6860 - val_loss: 1.0824 - val_accuracy: 0.4286\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0195 - accuracy: 0.6860 - val_loss: 1.0807 - val_accuracy: 0.4286\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0180 - accuracy: 0.6860 - val_loss: 1.0794 - val_accuracy: 0.4286\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0161 - accuracy: 0.6860 - val_loss: 1.0759 - val_accuracy: 0.4286\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0143 - accuracy: 0.6860 - val_loss: 1.0727 - val_accuracy: 0.4286\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0128 - accuracy: 0.6694 - val_loss: 1.0695 - val_accuracy: 0.4286\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0108 - accuracy: 0.6777 - val_loss: 1.0684 - val_accuracy: 0.4286\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0091 - accuracy: 0.6860 - val_loss: 1.0677 - val_accuracy: 0.4286\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0072 - accuracy: 0.6860 - val_loss: 1.0669 - val_accuracy: 0.4286\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0054 - accuracy: 0.6860 - val_loss: 1.0662 - val_accuracy: 0.4286\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0035 - accuracy: 0.6942 - val_loss: 1.0652 - val_accuracy: 0.4286\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0017 - accuracy: 0.6942 - val_loss: 1.0636 - val_accuracy: 0.4286\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9997 - accuracy: 0.6942 - val_loss: 1.0632 - val_accuracy: 0.4286\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9978 - accuracy: 0.6942 - val_loss: 1.0621 - val_accuracy: 0.4286\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9959 - accuracy: 0.6942 - val_loss: 1.0612 - val_accuracy: 0.4286\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9939 - accuracy: 0.6942 - val_loss: 1.0599 - val_accuracy: 0.4286\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9921 - accuracy: 0.6942 - val_loss: 1.0603 - val_accuracy: 0.4286\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9900 - accuracy: 0.6942 - val_loss: 1.0583 - val_accuracy: 0.4286\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9878 - accuracy: 0.6942 - val_loss: 1.0567 - val_accuracy: 0.4286\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9861 - accuracy: 0.6942 - val_loss: 1.0557 - val_accuracy: 0.4286\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.9838 - accuracy: 0.6942 - val_loss: 1.0547 - val_accuracy: 0.4286\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9818 - accuracy: 0.6942 - val_loss: 1.0536 - val_accuracy: 0.4286\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.9797 - accuracy: 0.6942 - val_loss: 1.0507 - val_accuracy: 0.4286\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9775 - accuracy: 0.6942 - val_loss: 1.0493 - val_accuracy: 0.4286\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9754 - accuracy: 0.6942 - val_loss: 1.0484 - val_accuracy: 0.4286\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9731 - accuracy: 0.6942 - val_loss: 1.0472 - val_accuracy: 0.4286\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9710 - accuracy: 0.6942 - val_loss: 1.0464 - val_accuracy: 0.4286\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9689 - accuracy: 0.6942 - val_loss: 1.0458 - val_accuracy: 0.4286\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9666 - accuracy: 0.6942 - val_loss: 1.0438 - val_accuracy: 0.4286\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9644 - accuracy: 0.6942 - val_loss: 1.0414 - val_accuracy: 0.4286\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9620 - accuracy: 0.6942 - val_loss: 1.0404 - val_accuracy: 0.4286\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9598 - accuracy: 0.6942 - val_loss: 1.0399 - val_accuracy: 0.4286\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9576 - accuracy: 0.6942 - val_loss: 1.0395 - val_accuracy: 0.4286\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9553 - accuracy: 0.6942 - val_loss: 1.0378 - val_accuracy: 0.4286\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.9528 - accuracy: 0.6942 - val_loss: 1.0352 - val_accuracy: 0.5000\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9505 - accuracy: 0.6942 - val_loss: 1.0317 - val_accuracy: 0.5000\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.9481 - accuracy: 0.6942 - val_loss: 1.0288 - val_accuracy: 0.5000\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9460 - accuracy: 0.6942 - val_loss: 1.0274 - val_accuracy: 0.5000\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9434 - accuracy: 0.6942 - val_loss: 1.0244 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9409 - accuracy: 0.6942 - val_loss: 1.0215 - val_accuracy: 0.5000\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9385 - accuracy: 0.6942 - val_loss: 1.0199 - val_accuracy: 0.5000\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9359 - accuracy: 0.6942 - val_loss: 1.0174 - val_accuracy: 0.5000\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9335 - accuracy: 0.6942 - val_loss: 1.0151 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9310 - accuracy: 0.6942 - val_loss: 1.0140 - val_accuracy: 0.5000\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9290 - accuracy: 0.6942 - val_loss: 1.0139 - val_accuracy: 0.5000\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9260 - accuracy: 0.6942 - val_loss: 1.0110 - val_accuracy: 0.5000\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9233 - accuracy: 0.6942 - val_loss: 1.0087 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9209 - accuracy: 0.6942 - val_loss: 1.0054 - val_accuracy: 0.5000\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9182 - accuracy: 0.6942 - val_loss: 1.0036 - val_accuracy: 0.5000\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9157 - accuracy: 0.6942 - val_loss: 1.0004 - val_accuracy: 0.5000\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9129 - accuracy: 0.6942 - val_loss: 0.9987 - val_accuracy: 0.5000\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9103 - accuracy: 0.6942 - val_loss: 0.9975 - val_accuracy: 0.5000\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9076 - accuracy: 0.6942 - val_loss: 0.9957 - val_accuracy: 0.5000\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9050 - accuracy: 0.6942 - val_loss: 0.9943 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9022 - accuracy: 0.6942 - val_loss: 0.9925 - val_accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8995 - accuracy: 0.6942 - val_loss: 0.9906 - val_accuracy: 0.5000\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8968 - accuracy: 0.6942 - val_loss: 0.9889 - val_accuracy: 0.5000\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8941 - accuracy: 0.6942 - val_loss: 0.9881 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8918 - accuracy: 0.6942 - val_loss: 0.9876 - val_accuracy: 0.5000\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8886 - accuracy: 0.6942 - val_loss: 0.9837 - val_accuracy: 0.5000\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8857 - accuracy: 0.6942 - val_loss: 0.9812 - val_accuracy: 0.5000\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8829 - accuracy: 0.6942 - val_loss: 0.9783 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8810 - accuracy: 0.6942 - val_loss: 0.9741 - val_accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8771 - accuracy: 0.6942 - val_loss: 0.9728 - val_accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8747 - accuracy: 0.6942 - val_loss: 0.9725 - val_accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8716 - accuracy: 0.6942 - val_loss: 0.9709 - val_accuracy: 0.5000\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8688 - accuracy: 0.6942 - val_loss: 0.9686 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8658 - accuracy: 0.6942 - val_loss: 0.9658 - val_accuracy: 0.5000\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8630 - accuracy: 0.6942 - val_loss: 0.9632 - val_accuracy: 0.5000\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8602 - accuracy: 0.6942 - val_loss: 0.9593 - val_accuracy: 0.5000\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8573 - accuracy: 0.6942 - val_loss: 0.9562 - val_accuracy: 0.5000\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8548 - accuracy: 0.6942 - val_loss: 0.9559 - val_accuracy: 0.5000\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8514 - accuracy: 0.6942 - val_loss: 0.9533 - val_accuracy: 0.5000\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8485 - accuracy: 0.6942 - val_loss: 0.9508 - val_accuracy: 0.5000\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8455 - accuracy: 0.6942 - val_loss: 0.9471 - val_accuracy: 0.5000\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.8431 - accuracy: 0.6942 - val_loss: 0.9425 - val_accuracy: 0.5000\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8398 - accuracy: 0.6942 - val_loss: 0.9409 - val_accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.8368 - accuracy: 0.6942 - val_loss: 0.9386 - val_accuracy: 0.5000\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8338 - accuracy: 0.6942 - val_loss: 0.9352 - val_accuracy: 0.5000\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8308 - accuracy: 0.6942 - val_loss: 0.9328 - val_accuracy: 0.5000\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8278 - accuracy: 0.6942 - val_loss: 0.9303 - val_accuracy: 0.5000\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8252 - accuracy: 0.6942 - val_loss: 0.9304 - val_accuracy: 0.5000\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8218 - accuracy: 0.6942 - val_loss: 0.9278 - val_accuracy: 0.5000\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8188 - accuracy: 0.6942 - val_loss: 0.9257 - val_accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8158 - accuracy: 0.6942 - val_loss: 0.9233 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8130 - accuracy: 0.6942 - val_loss: 0.9205 - val_accuracy: 0.5000\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8098 - accuracy: 0.6942 - val_loss: 0.9183 - val_accuracy: 0.5000\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8068 - accuracy: 0.6942 - val_loss: 0.9151 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.8039 - accuracy: 0.6942 - val_loss: 0.9135 - val_accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8008 - accuracy: 0.6942 - val_loss: 0.9115 - val_accuracy: 0.5000\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7977 - accuracy: 0.6942 - val_loss: 0.9080 - val_accuracy: 0.5000\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7947 - accuracy: 0.6942 - val_loss: 0.9047 - val_accuracy: 0.5000\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7916 - accuracy: 0.6942 - val_loss: 0.9017 - val_accuracy: 0.5000\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7887 - accuracy: 0.6942 - val_loss: 0.8999 - val_accuracy: 0.5000\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7856 - accuracy: 0.6942 - val_loss: 0.8979 - val_accuracy: 0.5000\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7828 - accuracy: 0.6942 - val_loss: 0.8954 - val_accuracy: 0.5000\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7795 - accuracy: 0.6942 - val_loss: 0.8922 - val_accuracy: 0.5000\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7765 - accuracy: 0.6942 - val_loss: 0.8884 - val_accuracy: 0.5000\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7734 - accuracy: 0.6942 - val_loss: 0.8860 - val_accuracy: 0.5000\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7705 - accuracy: 0.6942 - val_loss: 0.8828 - val_accuracy: 0.5000\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7675 - accuracy: 0.6942 - val_loss: 0.8815 - val_accuracy: 0.5000\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7645 - accuracy: 0.6942 - val_loss: 0.8788 - val_accuracy: 0.5000\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7618 - accuracy: 0.6942 - val_loss: 0.8785 - val_accuracy: 0.5000\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7583 - accuracy: 0.6942 - val_loss: 0.8758 - val_accuracy: 0.5000\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7555 - accuracy: 0.6942 - val_loss: 0.8742 - val_accuracy: 0.5000\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7524 - accuracy: 0.6942 - val_loss: 0.8711 - val_accuracy: 0.5000\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7493 - accuracy: 0.6942 - val_loss: 0.8684 - val_accuracy: 0.5000\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7464 - accuracy: 0.6942 - val_loss: 0.8657 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7435 - accuracy: 0.6942 - val_loss: 0.8619 - val_accuracy: 0.5000\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7405 - accuracy: 0.6942 - val_loss: 0.8584 - val_accuracy: 0.5000\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7374 - accuracy: 0.6942 - val_loss: 0.8562 - val_accuracy: 0.5000\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7346 - accuracy: 0.6942 - val_loss: 0.8529 - val_accuracy: 0.5000\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7316 - accuracy: 0.6942 - val_loss: 0.8517 - val_accuracy: 0.5000\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7287 - accuracy: 0.6942 - val_loss: 0.8507 - val_accuracy: 0.5000\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7257 - accuracy: 0.6942 - val_loss: 0.8477 - val_accuracy: 0.5000\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7227 - accuracy: 0.6942 - val_loss: 0.8444 - val_accuracy: 0.5000\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7198 - accuracy: 0.6942 - val_loss: 0.8417 - val_accuracy: 0.5000\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7169 - accuracy: 0.6942 - val_loss: 0.8394 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7140 - accuracy: 0.6942 - val_loss: 0.8366 - val_accuracy: 0.5000\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7113 - accuracy: 0.6942 - val_loss: 0.8333 - val_accuracy: 0.5000\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7082 - accuracy: 0.6942 - val_loss: 0.8316 - val_accuracy: 0.5000\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7054 - accuracy: 0.6942 - val_loss: 0.8292 - val_accuracy: 0.5000\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7026 - accuracy: 0.6942 - val_loss: 0.8263 - val_accuracy: 0.5000\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6997 - accuracy: 0.6942 - val_loss: 0.8247 - val_accuracy: 0.5000\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6970 - accuracy: 0.6942 - val_loss: 0.8224 - val_accuracy: 0.5000\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6941 - accuracy: 0.6942 - val_loss: 0.8194 - val_accuracy: 0.5000\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6913 - accuracy: 0.6942 - val_loss: 0.8152 - val_accuracy: 0.5000\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6886 - accuracy: 0.6942 - val_loss: 0.8121 - val_accuracy: 0.5000\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6858 - accuracy: 0.7025 - val_loss: 0.8086 - val_accuracy: 0.5000\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6832 - accuracy: 0.7025 - val_loss: 0.8065 - val_accuracy: 0.5000\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6803 - accuracy: 0.7025 - val_loss: 0.8048 - val_accuracy: 0.5000\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6775 - accuracy: 0.7025 - val_loss: 0.8029 - val_accuracy: 0.5000\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6750 - accuracy: 0.7025 - val_loss: 0.8016 - val_accuracy: 0.5000\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6723 - accuracy: 0.7025 - val_loss: 0.7980 - val_accuracy: 0.5000\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6695 - accuracy: 0.7107 - val_loss: 0.7958 - val_accuracy: 0.5000\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6671 - accuracy: 0.7107 - val_loss: 0.7913 - val_accuracy: 0.5000\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6643 - accuracy: 0.7190 - val_loss: 0.7887 - val_accuracy: 0.5000\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6615 - accuracy: 0.7190 - val_loss: 0.7867 - val_accuracy: 0.5000\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6589 - accuracy: 0.7190 - val_loss: 0.7854 - val_accuracy: 0.5000\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6564 - accuracy: 0.7107 - val_loss: 0.7835 - val_accuracy: 0.5000\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6540 - accuracy: 0.7190 - val_loss: 0.7798 - val_accuracy: 0.5000\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6513 - accuracy: 0.7190 - val_loss: 0.7780 - val_accuracy: 0.5000\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6487 - accuracy: 0.7107 - val_loss: 0.7756 - val_accuracy: 0.5000\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6462 - accuracy: 0.7190 - val_loss: 0.7732 - val_accuracy: 0.5000\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6437 - accuracy: 0.7190 - val_loss: 0.7705 - val_accuracy: 0.5000\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6414 - accuracy: 0.7190 - val_loss: 0.7692 - val_accuracy: 0.5000\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6389 - accuracy: 0.7190 - val_loss: 0.7652 - val_accuracy: 0.5000\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6365 - accuracy: 0.7190 - val_loss: 0.7624 - val_accuracy: 0.5000\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6339 - accuracy: 0.7190 - val_loss: 0.7598 - val_accuracy: 0.5000\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6315 - accuracy: 0.7190 - val_loss: 0.7577 - val_accuracy: 0.5000\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6292 - accuracy: 0.7190 - val_loss: 0.7557 - val_accuracy: 0.5000\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6267 - accuracy: 0.7190 - val_loss: 0.7535 - val_accuracy: 0.5000\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6244 - accuracy: 0.7190 - val_loss: 0.7505 - val_accuracy: 0.5000\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6221 - accuracy: 0.7190 - val_loss: 0.7481 - val_accuracy: 0.5000\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6201 - accuracy: 0.7355 - val_loss: 0.7442 - val_accuracy: 0.5000\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6175 - accuracy: 0.7355 - val_loss: 0.7436 - val_accuracy: 0.5000\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6151 - accuracy: 0.7355 - val_loss: 0.7417 - val_accuracy: 0.5000\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6129 - accuracy: 0.7355 - val_loss: 0.7398 - val_accuracy: 0.5000\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6107 - accuracy: 0.7273 - val_loss: 0.7377 - val_accuracy: 0.5000\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6085 - accuracy: 0.7355 - val_loss: 0.7350 - val_accuracy: 0.5000\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6067 - accuracy: 0.7190 - val_loss: 0.7342 - val_accuracy: 0.5000\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6042 - accuracy: 0.7355 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6019 - accuracy: 0.7355 - val_loss: 0.7271 - val_accuracy: 0.5000\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6000 - accuracy: 0.7438 - val_loss: 0.7232 - val_accuracy: 0.5000\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5976 - accuracy: 0.7438 - val_loss: 0.7217 - val_accuracy: 0.5000\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5954 - accuracy: 0.7438 - val_loss: 0.7193 - val_accuracy: 0.5000\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5934 - accuracy: 0.7438 - val_loss: 0.7168 - val_accuracy: 0.5000\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5913 - accuracy: 0.7438 - val_loss: 0.7150 - val_accuracy: 0.5000\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5894 - accuracy: 0.7438 - val_loss: 0.7125 - val_accuracy: 0.5000\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5871 - accuracy: 0.7438 - val_loss: 0.7114 - val_accuracy: 0.5000\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5851 - accuracy: 0.7438 - val_loss: 0.7098 - val_accuracy: 0.5000\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5831 - accuracy: 0.7438 - val_loss: 0.7092 - val_accuracy: 0.5000\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5813 - accuracy: 0.7438 - val_loss: 0.7074 - val_accuracy: 0.5000\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5792 - accuracy: 0.7438 - val_loss: 0.7071 - val_accuracy: 0.5000\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5774 - accuracy: 0.7355 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5753 - accuracy: 0.7355 - val_loss: 0.7038 - val_accuracy: 0.5000\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5734 - accuracy: 0.7355 - val_loss: 0.7013 - val_accuracy: 0.5000\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5717 - accuracy: 0.7438 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5696 - accuracy: 0.7438 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5678 - accuracy: 0.7438 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5659 - accuracy: 0.7438 - val_loss: 0.6897 - val_accuracy: 0.5000\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5640 - accuracy: 0.7521 - val_loss: 0.6866 - val_accuracy: 0.5714\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5625 - accuracy: 0.7603 - val_loss: 0.6827 - val_accuracy: 0.5714\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5606 - accuracy: 0.7603 - val_loss: 0.6816 - val_accuracy: 0.5714\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5589 - accuracy: 0.7603 - val_loss: 0.6782 - val_accuracy: 0.6429\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5570 - accuracy: 0.7603 - val_loss: 0.6776 - val_accuracy: 0.5714\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5551 - accuracy: 0.7603 - val_loss: 0.6761 - val_accuracy: 0.5714\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5535 - accuracy: 0.7603 - val_loss: 0.6738 - val_accuracy: 0.6429\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5520 - accuracy: 0.7603 - val_loss: 0.6746 - val_accuracy: 0.5714\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5500 - accuracy: 0.7603 - val_loss: 0.6723 - val_accuracy: 0.5714\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5485 - accuracy: 0.7603 - val_loss: 0.6724 - val_accuracy: 0.5714\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5468 - accuracy: 0.7521 - val_loss: 0.6714 - val_accuracy: 0.5714\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5449 - accuracy: 0.7521 - val_loss: 0.6681 - val_accuracy: 0.5714\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5437 - accuracy: 0.7603 - val_loss: 0.6637 - val_accuracy: 0.6429\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5416 - accuracy: 0.7603 - val_loss: 0.6613 - val_accuracy: 0.7143\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5401 - accuracy: 0.7603 - val_loss: 0.6594 - val_accuracy: 0.7143\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5386 - accuracy: 0.7603 - val_loss: 0.6592 - val_accuracy: 0.6429\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5368 - accuracy: 0.7603 - val_loss: 0.6577 - val_accuracy: 0.6429\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5353 - accuracy: 0.7603 - val_loss: 0.6558 - val_accuracy: 0.6429\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5337 - accuracy: 0.7603 - val_loss: 0.6544 - val_accuracy: 0.6429\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5322 - accuracy: 0.7603 - val_loss: 0.6533 - val_accuracy: 0.6429\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5308 - accuracy: 0.7603 - val_loss: 0.6506 - val_accuracy: 0.7143\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5291 - accuracy: 0.7603 - val_loss: 0.6498 - val_accuracy: 0.6429\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5277 - accuracy: 0.7603 - val_loss: 0.6489 - val_accuracy: 0.6429\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5262 - accuracy: 0.7603 - val_loss: 0.6463 - val_accuracy: 0.7143\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5247 - accuracy: 0.7603 - val_loss: 0.6448 - val_accuracy: 0.7143\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5232 - accuracy: 0.7603 - val_loss: 0.6432 - val_accuracy: 0.7143\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5217 - accuracy: 0.7603 - val_loss: 0.6414 - val_accuracy: 0.7143\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5204 - accuracy: 0.7603 - val_loss: 0.6391 - val_accuracy: 0.7143\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5189 - accuracy: 0.7603 - val_loss: 0.6374 - val_accuracy: 0.7143\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5176 - accuracy: 0.7603 - val_loss: 0.6379 - val_accuracy: 0.7143\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5161 - accuracy: 0.7603 - val_loss: 0.6366 - val_accuracy: 0.7143\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5148 - accuracy: 0.7603 - val_loss: 0.6360 - val_accuracy: 0.6429\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5133 - accuracy: 0.7603 - val_loss: 0.6337 - val_accuracy: 0.7143\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5122 - accuracy: 0.7603 - val_loss: 0.6333 - val_accuracy: 0.6429\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5108 - accuracy: 0.7603 - val_loss: 0.6296 - val_accuracy: 0.7143\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5093 - accuracy: 0.7603 - val_loss: 0.6266 - val_accuracy: 0.7143\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5079 - accuracy: 0.7603 - val_loss: 0.6253 - val_accuracy: 0.7143\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5066 - accuracy: 0.7603 - val_loss: 0.6234 - val_accuracy: 0.7143\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5053 - accuracy: 0.7603 - val_loss: 0.6228 - val_accuracy: 0.7143\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5039 - accuracy: 0.7603 - val_loss: 0.6208 - val_accuracy: 0.7143\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5026 - accuracy: 0.7686 - val_loss: 0.6192 - val_accuracy: 0.7143\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5014 - accuracy: 0.7686 - val_loss: 0.6179 - val_accuracy: 0.7143\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5001 - accuracy: 0.7686 - val_loss: 0.6165 - val_accuracy: 0.7143\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4989 - accuracy: 0.7769 - val_loss: 0.6147 - val_accuracy: 0.7143\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4977 - accuracy: 0.7851 - val_loss: 0.6119 - val_accuracy: 0.7143\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4964 - accuracy: 0.7934 - val_loss: 0.6095 - val_accuracy: 0.7143\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4952 - accuracy: 0.7934 - val_loss: 0.6088 - val_accuracy: 0.7143\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4941 - accuracy: 0.7934 - val_loss: 0.6058 - val_accuracy: 0.7143\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4927 - accuracy: 0.8017 - val_loss: 0.6044 - val_accuracy: 0.7143\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4915 - accuracy: 0.8017 - val_loss: 0.6031 - val_accuracy: 0.7143\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4903 - accuracy: 0.8017 - val_loss: 0.6022 - val_accuracy: 0.7143\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4892 - accuracy: 0.8017 - val_loss: 0.6022 - val_accuracy: 0.7143\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4881 - accuracy: 0.7934 - val_loss: 0.6017 - val_accuracy: 0.7143\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4869 - accuracy: 0.7934 - val_loss: 0.5991 - val_accuracy: 0.7143\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4859 - accuracy: 0.8017 - val_loss: 0.5961 - val_accuracy: 0.7143\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4845 - accuracy: 0.8099 - val_loss: 0.5949 - val_accuracy: 0.7143\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4836 - accuracy: 0.8099 - val_loss: 0.5957 - val_accuracy: 0.7143\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4822 - accuracy: 0.8017 - val_loss: 0.5951 - val_accuracy: 0.7143\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4812 - accuracy: 0.8017 - val_loss: 0.5935 - val_accuracy: 0.7143\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4801 - accuracy: 0.8099 - val_loss: 0.5920 - val_accuracy: 0.7143\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4790 - accuracy: 0.8099 - val_loss: 0.5904 - val_accuracy: 0.7143\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4778 - accuracy: 0.8099 - val_loss: 0.5900 - val_accuracy: 0.7143\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4769 - accuracy: 0.8017 - val_loss: 0.5897 - val_accuracy: 0.7143\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4756 - accuracy: 0.8017 - val_loss: 0.5870 - val_accuracy: 0.7143\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4749 - accuracy: 0.8099 - val_loss: 0.5837 - val_accuracy: 0.7143\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4738 - accuracy: 0.8182 - val_loss: 0.5806 - val_accuracy: 0.7857\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4725 - accuracy: 0.8347 - val_loss: 0.5798 - val_accuracy: 0.7857\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4714 - accuracy: 0.8347 - val_loss: 0.5786 - val_accuracy: 0.7857\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4704 - accuracy: 0.8099 - val_loss: 0.5785 - val_accuracy: 0.7143\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4694 - accuracy: 0.8099 - val_loss: 0.5781 - val_accuracy: 0.7143\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4686 - accuracy: 0.8264 - val_loss: 0.5752 - val_accuracy: 0.7857\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4674 - accuracy: 0.8264 - val_loss: 0.5754 - val_accuracy: 0.7143\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4662 - accuracy: 0.8264 - val_loss: 0.5738 - val_accuracy: 0.7857\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4652 - accuracy: 0.8264 - val_loss: 0.5722 - val_accuracy: 0.7857\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4644 - accuracy: 0.8264 - val_loss: 0.5720 - val_accuracy: 0.7143\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4632 - accuracy: 0.8264 - val_loss: 0.5707 - val_accuracy: 0.7857\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4628 - accuracy: 0.8430 - val_loss: 0.5672 - val_accuracy: 0.7857\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4614 - accuracy: 0.8512 - val_loss: 0.5664 - val_accuracy: 0.7857\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4605 - accuracy: 0.8347 - val_loss: 0.5653 - val_accuracy: 0.7857\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4594 - accuracy: 0.8347 - val_loss: 0.5645 - val_accuracy: 0.7857\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4585 - accuracy: 0.8347 - val_loss: 0.5632 - val_accuracy: 0.7857\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4575 - accuracy: 0.8595 - val_loss: 0.5612 - val_accuracy: 0.8571\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4565 - accuracy: 0.8595 - val_loss: 0.5593 - val_accuracy: 0.8571\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4558 - accuracy: 0.8595 - val_loss: 0.5575 - val_accuracy: 0.8571\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4549 - accuracy: 0.8595 - val_loss: 0.5583 - val_accuracy: 0.7857\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4539 - accuracy: 0.8595 - val_loss: 0.5572 - val_accuracy: 0.8571\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4529 - accuracy: 0.8595 - val_loss: 0.5546 - val_accuracy: 0.8571\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4521 - accuracy: 0.8595 - val_loss: 0.5549 - val_accuracy: 0.8571\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4510 - accuracy: 0.8595 - val_loss: 0.5535 - val_accuracy: 0.8571\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4501 - accuracy: 0.8595 - val_loss: 0.5518 - val_accuracy: 0.8571\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4492 - accuracy: 0.8595 - val_loss: 0.5513 - val_accuracy: 0.8571\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4484 - accuracy: 0.8595 - val_loss: 0.5496 - val_accuracy: 0.8571\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4474 - accuracy: 0.8595 - val_loss: 0.5488 - val_accuracy: 0.8571\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4467 - accuracy: 0.8595 - val_loss: 0.5491 - val_accuracy: 0.8571\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4457 - accuracy: 0.8595 - val_loss: 0.5485 - val_accuracy: 0.8571\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4448 - accuracy: 0.8595 - val_loss: 0.5472 - val_accuracy: 0.8571\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4439 - accuracy: 0.8595 - val_loss: 0.5459 - val_accuracy: 0.8571\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4430 - accuracy: 0.8595 - val_loss: 0.5449 - val_accuracy: 0.8571\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4422 - accuracy: 0.8595 - val_loss: 0.5437 - val_accuracy: 0.8571\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4414 - accuracy: 0.8595 - val_loss: 0.5426 - val_accuracy: 0.8571\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4405 - accuracy: 0.8595 - val_loss: 0.5408 - val_accuracy: 0.9286\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4396 - accuracy: 0.8678 - val_loss: 0.5394 - val_accuracy: 0.9286\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4389 - accuracy: 0.8678 - val_loss: 0.5392 - val_accuracy: 0.9286\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4381 - accuracy: 0.8595 - val_loss: 0.5391 - val_accuracy: 0.8571\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4371 - accuracy: 0.8595 - val_loss: 0.5365 - val_accuracy: 0.9286\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4363 - accuracy: 0.8678 - val_loss: 0.5340 - val_accuracy: 0.9286\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4360 - accuracy: 0.8678 - val_loss: 0.5342 - val_accuracy: 0.9286\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4347 - accuracy: 0.8678 - val_loss: 0.5311 - val_accuracy: 0.9286\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4340 - accuracy: 0.8760 - val_loss: 0.5286 - val_accuracy: 0.9286\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4332 - accuracy: 0.8926 - val_loss: 0.5253 - val_accuracy: 0.9286\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4330 - accuracy: 0.9008 - val_loss: 0.5226 - val_accuracy: 0.9286\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4316 - accuracy: 0.9091 - val_loss: 0.5226 - val_accuracy: 0.9286\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4314 - accuracy: 0.9008 - val_loss: 0.5250 - val_accuracy: 0.9286\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4299 - accuracy: 0.8843 - val_loss: 0.5247 - val_accuracy: 0.9286\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4291 - accuracy: 0.8843 - val_loss: 0.5237 - val_accuracy: 0.9286\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4286 - accuracy: 0.8843 - val_loss: 0.5213 - val_accuracy: 0.9286\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4275 - accuracy: 0.9008 - val_loss: 0.5211 - val_accuracy: 0.9286\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4267 - accuracy: 0.8843 - val_loss: 0.5213 - val_accuracy: 0.9286\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4259 - accuracy: 0.8843 - val_loss: 0.5209 - val_accuracy: 0.9286\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4252 - accuracy: 0.8843 - val_loss: 0.5202 - val_accuracy: 0.9286\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4245 - accuracy: 0.8760 - val_loss: 0.5193 - val_accuracy: 0.9286\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4237 - accuracy: 0.8843 - val_loss: 0.5186 - val_accuracy: 0.9286\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4232 - accuracy: 0.8760 - val_loss: 0.5198 - val_accuracy: 0.9286\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4222 - accuracy: 0.8760 - val_loss: 0.5188 - val_accuracy: 0.9286\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4218 - accuracy: 0.8678 - val_loss: 0.5185 - val_accuracy: 0.9286\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4206 - accuracy: 0.8678 - val_loss: 0.5157 - val_accuracy: 0.9286\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4199 - accuracy: 0.8926 - val_loss: 0.5129 - val_accuracy: 0.9286\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4191 - accuracy: 0.9008 - val_loss: 0.5109 - val_accuracy: 0.9286\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4186 - accuracy: 0.9008 - val_loss: 0.5082 - val_accuracy: 0.9286\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4180 - accuracy: 0.9008 - val_loss: 0.5084 - val_accuracy: 0.9286\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4170 - accuracy: 0.9008 - val_loss: 0.5078 - val_accuracy: 0.9286\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4166 - accuracy: 0.9008 - val_loss: 0.5087 - val_accuracy: 0.9286\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4156 - accuracy: 0.8926 - val_loss: 0.5080 - val_accuracy: 0.9286\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4148 - accuracy: 0.9008 - val_loss: 0.5066 - val_accuracy: 0.9286\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4141 - accuracy: 0.9008 - val_loss: 0.5053 - val_accuracy: 0.9286\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4134 - accuracy: 0.9008 - val_loss: 0.5030 - val_accuracy: 0.9286\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4129 - accuracy: 0.9091 - val_loss: 0.5006 - val_accuracy: 0.9286\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4122 - accuracy: 0.9091 - val_loss: 0.5016 - val_accuracy: 0.9286\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4113 - accuracy: 0.9008 - val_loss: 0.5014 - val_accuracy: 0.9286\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4107 - accuracy: 0.9008 - val_loss: 0.4993 - val_accuracy: 0.9286\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4099 - accuracy: 0.9091 - val_loss: 0.4989 - val_accuracy: 0.9286\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4092 - accuracy: 0.9008 - val_loss: 0.4990 - val_accuracy: 0.9286\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4085 - accuracy: 0.9008 - val_loss: 0.4983 - val_accuracy: 0.9286\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4077 - accuracy: 0.9008 - val_loss: 0.4967 - val_accuracy: 0.9286\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4070 - accuracy: 0.9008 - val_loss: 0.4961 - val_accuracy: 0.9286\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4065 - accuracy: 0.9091 - val_loss: 0.4939 - val_accuracy: 0.9286\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4057 - accuracy: 0.9091 - val_loss: 0.4928 - val_accuracy: 0.9286\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4049 - accuracy: 0.9091 - val_loss: 0.4925 - val_accuracy: 0.9286\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4042 - accuracy: 0.9091 - val_loss: 0.4920 - val_accuracy: 0.9286\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4040 - accuracy: 0.9008 - val_loss: 0.4936 - val_accuracy: 0.9286\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4033 - accuracy: 0.9008 - val_loss: 0.4938 - val_accuracy: 0.9286\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4022 - accuracy: 0.9008 - val_loss: 0.4911 - val_accuracy: 0.9286\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4018 - accuracy: 0.9008 - val_loss: 0.4875 - val_accuracy: 0.9286\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4009 - accuracy: 0.9091 - val_loss: 0.4855 - val_accuracy: 0.9286\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4003 - accuracy: 0.9256 - val_loss: 0.4842 - val_accuracy: 0.9286\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3996 - accuracy: 0.9256 - val_loss: 0.4836 - val_accuracy: 0.9286\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3989 - accuracy: 0.9339 - val_loss: 0.4821 - val_accuracy: 0.9286\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3983 - accuracy: 0.9339 - val_loss: 0.4818 - val_accuracy: 0.9286\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3975 - accuracy: 0.9339 - val_loss: 0.4807 - val_accuracy: 0.9286\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3973 - accuracy: 0.9339 - val_loss: 0.4787 - val_accuracy: 0.9286\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3966 - accuracy: 0.9256 - val_loss: 0.4807 - val_accuracy: 0.9286\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3956 - accuracy: 0.9174 - val_loss: 0.4810 - val_accuracy: 0.9286\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3949 - accuracy: 0.9091 - val_loss: 0.4800 - val_accuracy: 0.9286\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3943 - accuracy: 0.9174 - val_loss: 0.4782 - val_accuracy: 0.9286\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3936 - accuracy: 0.9256 - val_loss: 0.4781 - val_accuracy: 0.9286\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3929 - accuracy: 0.9256 - val_loss: 0.4762 - val_accuracy: 0.9286\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3922 - accuracy: 0.9339 - val_loss: 0.4752 - val_accuracy: 0.9286\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3916 - accuracy: 0.9339 - val_loss: 0.4740 - val_accuracy: 0.9286\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3909 - accuracy: 0.9339 - val_loss: 0.4721 - val_accuracy: 0.9286\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3904 - accuracy: 0.9339 - val_loss: 0.4710 - val_accuracy: 0.9286\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3897 - accuracy: 0.9339 - val_loss: 0.4700 - val_accuracy: 0.9286\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3890 - accuracy: 0.9339 - val_loss: 0.4685 - val_accuracy: 0.9286\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3884 - accuracy: 0.9339 - val_loss: 0.4681 - val_accuracy: 0.9286\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3878 - accuracy: 0.9339 - val_loss: 0.4669 - val_accuracy: 0.9286\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3872 - accuracy: 0.9339 - val_loss: 0.4664 - val_accuracy: 0.9286\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3864 - accuracy: 0.9339 - val_loss: 0.4663 - val_accuracy: 0.9286\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3859 - accuracy: 0.9339 - val_loss: 0.4664 - val_accuracy: 0.9286\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3852 - accuracy: 0.9339 - val_loss: 0.4656 - val_accuracy: 0.9286\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3845 - accuracy: 0.9339 - val_loss: 0.4661 - val_accuracy: 0.9286\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3840 - accuracy: 0.9339 - val_loss: 0.4664 - val_accuracy: 0.9286\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3834 - accuracy: 0.9339 - val_loss: 0.4643 - val_accuracy: 0.9286\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3827 - accuracy: 0.9339 - val_loss: 0.4632 - val_accuracy: 0.9286\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3821 - accuracy: 0.9339 - val_loss: 0.4614 - val_accuracy: 0.9286\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3815 - accuracy: 0.9339 - val_loss: 0.4608 - val_accuracy: 0.9286\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3808 - accuracy: 0.9339 - val_loss: 0.4590 - val_accuracy: 0.9286\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3801 - accuracy: 0.9339 - val_loss: 0.4586 - val_accuracy: 0.9286\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3796 - accuracy: 0.9339 - val_loss: 0.4574 - val_accuracy: 0.9286\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3793 - accuracy: 0.9339 - val_loss: 0.4561 - val_accuracy: 0.9286\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3782 - accuracy: 0.9339 - val_loss: 0.4567 - val_accuracy: 0.9286\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3778 - accuracy: 0.9339 - val_loss: 0.4557 - val_accuracy: 0.9286\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3771 - accuracy: 0.9339 - val_loss: 0.4559 - val_accuracy: 0.9286\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3766 - accuracy: 0.9339 - val_loss: 0.4572 - val_accuracy: 0.9286\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3759 - accuracy: 0.9339 - val_loss: 0.4565 - val_accuracy: 0.9286\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3754 - accuracy: 0.9339 - val_loss: 0.4547 - val_accuracy: 0.9286\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3747 - accuracy: 0.9339 - val_loss: 0.4543 - val_accuracy: 0.9286\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3741 - accuracy: 0.9339 - val_loss: 0.4523 - val_accuracy: 0.9286\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3736 - accuracy: 0.9339 - val_loss: 0.4526 - val_accuracy: 0.9286\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3729 - accuracy: 0.9339 - val_loss: 0.4504 - val_accuracy: 0.9286\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3724 - accuracy: 0.9339 - val_loss: 0.4480 - val_accuracy: 0.9286\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3716 - accuracy: 0.9339 - val_loss: 0.4468 - val_accuracy: 0.9286\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3715 - accuracy: 0.9339 - val_loss: 0.4444 - val_accuracy: 0.9286\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3704 - accuracy: 0.9339 - val_loss: 0.4441 - val_accuracy: 0.9286\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3699 - accuracy: 0.9339 - val_loss: 0.4453 - val_accuracy: 0.9286\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3692 - accuracy: 0.9339 - val_loss: 0.4454 - val_accuracy: 0.9286\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3686 - accuracy: 0.9339 - val_loss: 0.4445 - val_accuracy: 0.9286\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3680 - accuracy: 0.9339 - val_loss: 0.4423 - val_accuracy: 0.9286\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3674 - accuracy: 0.9339 - val_loss: 0.4418 - val_accuracy: 0.9286\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3671 - accuracy: 0.9339 - val_loss: 0.4389 - val_accuracy: 0.9286\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3662 - accuracy: 0.9339 - val_loss: 0.4380 - val_accuracy: 0.9286\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3657 - accuracy: 0.9339 - val_loss: 0.4362 - val_accuracy: 0.9286\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3656 - accuracy: 0.9339 - val_loss: 0.4380 - val_accuracy: 0.9286\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3645 - accuracy: 0.9339 - val_loss: 0.4366 - val_accuracy: 0.9286\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3641 - accuracy: 0.9339 - val_loss: 0.4372 - val_accuracy: 0.9286\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3635 - accuracy: 0.9339 - val_loss: 0.4339 - val_accuracy: 0.9286\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3628 - accuracy: 0.9339 - val_loss: 0.4320 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3622 - accuracy: 0.9339 - val_loss: 0.4308 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3614 - accuracy: 0.9339 - val_loss: 0.4316 - val_accuracy: 0.9286\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3608 - accuracy: 0.9339 - val_loss: 0.4313 - val_accuracy: 0.9286\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3603 - accuracy: 0.9339 - val_loss: 0.4315 - val_accuracy: 0.9286\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3597 - accuracy: 0.9339 - val_loss: 0.4305 - val_accuracy: 0.9286\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3590 - accuracy: 0.9339 - val_loss: 0.4302 - val_accuracy: 0.9286\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3585 - accuracy: 0.9339 - val_loss: 0.4304 - val_accuracy: 0.9286\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3579 - accuracy: 0.9339 - val_loss: 0.4300 - val_accuracy: 0.9286\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3573 - accuracy: 0.9339 - val_loss: 0.4293 - val_accuracy: 0.9286\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3568 - accuracy: 0.9339 - val_loss: 0.4283 - val_accuracy: 0.9286\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3564 - accuracy: 0.9339 - val_loss: 0.4264 - val_accuracy: 0.9286\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3556 - accuracy: 0.9339 - val_loss: 0.4259 - val_accuracy: 0.9286\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3550 - accuracy: 0.9339 - val_loss: 0.4252 - val_accuracy: 0.9286\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3545 - accuracy: 0.9339 - val_loss: 0.4255 - val_accuracy: 0.9286\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3539 - accuracy: 0.9339 - val_loss: 0.4251 - val_accuracy: 0.9286\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3533 - accuracy: 0.9339 - val_loss: 0.4238 - val_accuracy: 0.9286\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3527 - accuracy: 0.9339 - val_loss: 0.4215 - val_accuracy: 0.9286\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3521 - accuracy: 0.9339 - val_loss: 0.4202 - val_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3515 - accuracy: 0.9339 - val_loss: 0.4190 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3511 - accuracy: 0.9339 - val_loss: 0.4179 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3503 - accuracy: 0.9421 - val_loss: 0.4155 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3498 - accuracy: 0.9421 - val_loss: 0.4139 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3493 - accuracy: 0.9421 - val_loss: 0.4129 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3488 - accuracy: 0.9504 - val_loss: 0.4111 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3482 - accuracy: 0.9504 - val_loss: 0.4110 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3476 - accuracy: 0.9504 - val_loss: 0.4109 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3469 - accuracy: 0.9504 - val_loss: 0.4108 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3464 - accuracy: 0.9421 - val_loss: 0.4101 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3459 - accuracy: 0.9421 - val_loss: 0.4110 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3454 - accuracy: 0.9421 - val_loss: 0.4101 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3449 - accuracy: 0.9421 - val_loss: 0.4083 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3446 - accuracy: 0.9421 - val_loss: 0.4098 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3435 - accuracy: 0.9421 - val_loss: 0.4088 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3433 - accuracy: 0.9339 - val_loss: 0.4088 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3424 - accuracy: 0.9421 - val_loss: 0.4060 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3419 - accuracy: 0.9504 - val_loss: 0.4045 - val_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3412 - accuracy: 0.9504 - val_loss: 0.4027 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3408 - accuracy: 0.9504 - val_loss: 0.4007 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3404 - accuracy: 0.9504 - val_loss: 0.3990 - val_accuracy: 0.9286\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3400 - accuracy: 0.9504 - val_loss: 0.4005 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3392 - accuracy: 0.9504 - val_loss: 0.3998 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3385 - accuracy: 0.9504 - val_loss: 0.3991 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3382 - accuracy: 0.9504 - val_loss: 0.4001 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3373 - accuracy: 0.9504 - val_loss: 0.3986 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3368 - accuracy: 0.9504 - val_loss: 0.3973 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3363 - accuracy: 0.9504 - val_loss: 0.3971 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3357 - accuracy: 0.9504 - val_loss: 0.3966 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3352 - accuracy: 0.9504 - val_loss: 0.3950 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3346 - accuracy: 0.9504 - val_loss: 0.3955 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3340 - accuracy: 0.9504 - val_loss: 0.3947 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3335 - accuracy: 0.9504 - val_loss: 0.3944 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3330 - accuracy: 0.9504 - val_loss: 0.3937 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3330 - accuracy: 0.9504 - val_loss: 0.3900 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3319 - accuracy: 0.9504 - val_loss: 0.3893 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3313 - accuracy: 0.9504 - val_loss: 0.3892 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3308 - accuracy: 0.9504 - val_loss: 0.3883 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3302 - accuracy: 0.9504 - val_loss: 0.3895 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3298 - accuracy: 0.9504 - val_loss: 0.3905 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3293 - accuracy: 0.9504 - val_loss: 0.3887 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3285 - accuracy: 0.9504 - val_loss: 0.3878 - val_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3285 - accuracy: 0.9504 - val_loss: 0.3890 - val_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3274 - accuracy: 0.9504 - val_loss: 0.3870 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3271 - accuracy: 0.9504 - val_loss: 0.3842 - val_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3265 - accuracy: 0.9504 - val_loss: 0.3831 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3262 - accuracy: 0.9504 - val_loss: 0.3840 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3253 - accuracy: 0.9504 - val_loss: 0.3834 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3247 - accuracy: 0.9504 - val_loss: 0.3816 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3244 - accuracy: 0.9504 - val_loss: 0.3815 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3237 - accuracy: 0.9504 - val_loss: 0.3790 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3232 - accuracy: 0.9504 - val_loss: 0.3776 - val_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3231 - accuracy: 0.9504 - val_loss: 0.3751 - val_accuracy: 0.9286\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3221 - accuracy: 0.9587 - val_loss: 0.3756 - val_accuracy: 0.9286\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3218 - accuracy: 0.9504 - val_loss: 0.3770 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3211 - accuracy: 0.9504 - val_loss: 0.3772 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3204 - accuracy: 0.9504 - val_loss: 0.3763 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3198 - accuracy: 0.9504 - val_loss: 0.3750 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3194 - accuracy: 0.9504 - val_loss: 0.3734 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3190 - accuracy: 0.9504 - val_loss: 0.3719 - val_accuracy: 0.9286\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3182 - accuracy: 0.9504 - val_loss: 0.3725 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3178 - accuracy: 0.9504 - val_loss: 0.3725 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3172 - accuracy: 0.9504 - val_loss: 0.3727 - val_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3167 - accuracy: 0.9504 - val_loss: 0.3720 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3162 - accuracy: 0.9504 - val_loss: 0.3706 - val_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3156 - accuracy: 0.9504 - val_loss: 0.3698 - val_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3151 - accuracy: 0.9504 - val_loss: 0.3692 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3147 - accuracy: 0.9504 - val_loss: 0.3680 - val_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3140 - accuracy: 0.9504 - val_loss: 0.3677 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3135 - accuracy: 0.9504 - val_loss: 0.3675 - val_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3130 - accuracy: 0.9504 - val_loss: 0.3663 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3125 - accuracy: 0.9504 - val_loss: 0.3641 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3119 - accuracy: 0.9587 - val_loss: 0.3631 - val_accuracy: 0.9286\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3113 - accuracy: 0.9587 - val_loss: 0.3624 - val_accuracy: 0.9286\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3109 - accuracy: 0.9587 - val_loss: 0.3624 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3102 - accuracy: 0.9587 - val_loss: 0.3616 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3098 - accuracy: 0.9587 - val_loss: 0.3610 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3093 - accuracy: 0.9587 - val_loss: 0.3603 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3088 - accuracy: 0.9587 - val_loss: 0.3586 - val_accuracy: 0.9286\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3083 - accuracy: 0.9587 - val_loss: 0.3584 - val_accuracy: 0.9286\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3077 - accuracy: 0.9587 - val_loss: 0.3572 - val_accuracy: 0.9286\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3072 - accuracy: 0.9587 - val_loss: 0.3569 - val_accuracy: 0.9286\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3067 - accuracy: 0.9587 - val_loss: 0.3553 - val_accuracy: 0.9286\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3062 - accuracy: 0.9587 - val_loss: 0.3555 - val_accuracy: 0.9286\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3062 - accuracy: 0.9587 - val_loss: 0.3535 - val_accuracy: 0.9286\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3051 - accuracy: 0.9587 - val_loss: 0.3544 - val_accuracy: 0.9286\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3045 - accuracy: 0.9587 - val_loss: 0.3552 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3046 - accuracy: 0.9504 - val_loss: 0.3564 - val_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3035 - accuracy: 0.9504 - val_loss: 0.3546 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3032 - accuracy: 0.9587 - val_loss: 0.3518 - val_accuracy: 0.9286\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3026 - accuracy: 0.9587 - val_loss: 0.3500 - val_accuracy: 0.9286\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3020 - accuracy: 0.9587 - val_loss: 0.3491 - val_accuracy: 0.9286\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3015 - accuracy: 0.9587 - val_loss: 0.3491 - val_accuracy: 0.9286\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3010 - accuracy: 0.9587 - val_loss: 0.3491 - val_accuracy: 0.9286\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3006 - accuracy: 0.9587 - val_loss: 0.3491 - val_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2999 - accuracy: 0.9587 - val_loss: 0.3482 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2995 - accuracy: 0.9587 - val_loss: 0.3473 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2990 - accuracy: 0.9587 - val_loss: 0.3451 - val_accuracy: 0.9286\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2986 - accuracy: 0.9587 - val_loss: 0.3434 - val_accuracy: 0.9286\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2982 - accuracy: 0.9587 - val_loss: 0.3446 - val_accuracy: 0.9286\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2974 - accuracy: 0.9587 - val_loss: 0.3447 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2969 - accuracy: 0.9587 - val_loss: 0.3446 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2963 - accuracy: 0.9587 - val_loss: 0.3430 - val_accuracy: 0.9286\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2959 - accuracy: 0.9587 - val_loss: 0.3422 - val_accuracy: 0.9286\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2953 - accuracy: 0.9587 - val_loss: 0.3408 - val_accuracy: 0.9286\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2949 - accuracy: 0.9587 - val_loss: 0.3388 - val_accuracy: 0.9286\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2944 - accuracy: 0.9587 - val_loss: 0.3375 - val_accuracy: 0.9286\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2938 - accuracy: 0.9587 - val_loss: 0.3378 - val_accuracy: 0.9286\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2933 - accuracy: 0.9587 - val_loss: 0.3383 - val_accuracy: 0.9286\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2928 - accuracy: 0.9587 - val_loss: 0.3383 - val_accuracy: 0.9286\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2923 - accuracy: 0.9587 - val_loss: 0.3383 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2703 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 596.\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2919 - accuracy: 0.9587 - val_loss: 0.3388 - val_accuracy: 1.0000\n",
      "Epoch 601: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2168407d310>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train_l, x_train_w], y_train, validation_split=0.1,\n",
    "          epochs=1000, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3714 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3713569641113281, 0.9333333373069763]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_val_l, x_val_w], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 1, 2, 0, 2, 1, 1, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict([x_val_l, x_val_w])\n",
    "pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 1, 2, 0, 2, 1, 1, 2, 2, 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN ( Convoluttional Neural Networks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f7678e3cf7566e35dc0bd53f9a2e61d18c90ac4f700ab60c30179035bddd9e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
