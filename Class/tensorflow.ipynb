{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning ( TensorFlow )\n",
    "* https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netural Network\n",
    "- features(x) -> neuron -> target(y)\n",
    "    - ex) 주택 가격  \n",
    "    features(크기, 위치, 형태, ..) -> neuron(가중치, 그래프, 관계) -> target(가격)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,20))\n",
    "y = x * 2 - 1\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kears 모델 클리어\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# keras 모델 선언\n",
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 노드 조립\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# 컴파일\n",
    "# loss : 예측값 평가 기준 \n",
    "# optimizer : \n",
    "model.compile(loss='mse'\n",
    "              , optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs : 학습 횟수\n",
    "# verbose : 학습 과정 표현\n",
    "model.fit(x,y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,40)) \n",
    "y = np.array([0, 1] * 20)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              , optimizer='adam'\n",
    "              , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = x * 2 -1\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "\n",
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN / MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "# id = 0\n",
    "\n",
    "print(f'id = {id}')\n",
    "print(f'다음 그림은 숫자 {y_train[id]} 입니다.')\n",
    "\n",
    "plt.imshow(x_train[id])\n",
    "plt.show()\n",
    "\n",
    "# print(x_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[0], x_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3차원 -> 2차원\n",
    "x_train = x_train.reshape([x_train.shape[0],-1])\n",
    "x_val = x_val.reshape([x_val.shape[0],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'max : {x_train.max()} / min : {x_train.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n, min_n = x_train.max(), x_train.min()\n",
    "\n",
    "max_n, min_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train[0] - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - min_n) / (max_n - min_n)\n",
    "x_val = (x_val - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Sequential API\n",
    "# # 1. 세션 클리어\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# # 2. 모델 선언 : Sequential()\n",
    "# model = keras.models.Sequential()\n",
    "\n",
    "# # 3. 레이어 조립 : .add()\n",
    "# model.add( keras.layers.Input(shape=(784,)) )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add( keras.layers.Dense(10, activation='softmax') )\n",
    "\n",
    "# # 4. 컴파일\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "#               optimizer=keras.optimizers.Adam(0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functional API\n",
    "# 1. 세션 클리어\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 2. 레이어 사슬처럼 엮기\n",
    "il = keras.layers.Input(shape=(784,))\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "ol = keras.layers.Dense(10, activation='softmax')(il)\n",
    "\n",
    "# 3. 모델의 시작과 끝 지정\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "# 4. 컴파일\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', # 관측 대상\n",
    "                   min_delta=0,        # 최소한 나빠지지 않으면 괜찮아\n",
    "                   patience=5,         # 성능 개선되지 않는 걸 얼마나 참을래?\n",
    "                   verbose=1,\n",
    "                   restore_best_weights=True # 학습이 멈췄을 때, 최적의 가중치로 전환해줌\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=50, verbose=1,\n",
    "          validation_split=0.2,    # Train data의 20%를 Validation data로!\n",
    "          callbacks=[es]           # Early Stopping 적용\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "pred_val = model.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train.shape, pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_val = pred_val.argmax(axis=1)\n",
    "single_pred_train.shape, single_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_train_accuracy = accuracy_score(y_train.argmax(axis=1), single_pred_train)\n",
    "logi_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_test_accuracy = accuracy_score(y_val.argmax(axis=1), single_pred_val)\n",
    "logi_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i, index in enumerate(np.random.choice(x_val.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1)\n",
    "    # Display each image\n",
    "    ax.imshow(x_val[index].reshape([28,-1]), cmap='gray' )\n",
    "    \n",
    "    predict_index = pred_val[index].argmax(axis=0)\n",
    "    true_index = y_val[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(f\"{mnist_labels[predict_index]} ({mnist_labels[true_index]})\",\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) 3차원 array 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.array(\n",
    "    [\n",
    "        [\n",
    "                       [0, 0],\n",
    "                       [2,-1],\n",
    "                       [1, 0],\n",
    "                       [2, 2],\n",
    "        ],\n",
    "        [\n",
    "                       [1, 1],\n",
    "                       [3, 3],\n",
    "                       [2,-1],\n",
    "                       [1, 1],\n",
    "        ],\n",
    "        [\n",
    "                       [2, 2],\n",
    "                       [7,-1],\n",
    "                       [8, 1],\n",
    "                       [1, 0],\n",
    "        ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample   = n1.shape[0] # 3 (3개 샘플 데이터)\n",
    "num_sequence = n1.shape[1] # 4 (4개 시계열 데이터)\n",
    "num_feature  = n1.shape[2] # 2 (2개 Feature(미세먼지, 초미세먼지 증감))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열을 선회하면서 피팅합니다\n",
    "for ss in range(num_sequence):\n",
    "    print('ss', ss)\n",
    "    print(n1[:, ss, :])\n",
    "    print()\n",
    "    scaler.partial_fit(n1[:, ss, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링(변환)합니다.\n",
    "results = []\n",
    "for ss in range(num_sequence):\n",
    "    results.append(scaler.transform(n1[:, ss, :]).reshape(num_sample, 1, num_feature))\n",
    "\n",
    "print(results)\n",
    "print()\n",
    "\n",
    "n1_scaled = np.concatenate(results, axis=1)\n",
    "print(n1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) tensorflow GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://afsdzvcx123.tistory.com/entry/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-Windows%EC%9C%88%EB%8F%84%EC%9A%B0-CUDA-cuDNN-%EC%84%A4%EC%B9%98%EB%B0%A9%EB%B2%95\n",
    "* https://doitgrow.com/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13427346610800829377\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254700544\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7411534314026108379\n",
      "physical_device_desc: \"device: 0, name: Quadro T1000 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# GPU 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gpu 사용\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu 사용\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 0 : 'Airplane',\n",
    "          1 : 'Automobile',\n",
    "          2 : 'Bird',\n",
    "          3 : 'Cat',\n",
    "          4 : 'Deer',\n",
    "          5 : 'Dog',\n",
    "          6 : 'Frog',\n",
    "          7 : 'Horse',\n",
    "          8 : 'Ship',\n",
    "          9 : 'Truck' }\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "\n",
    "print('id = {}'.format(id))\n",
    "print('다음 그림은 {} 입니다.'.format( labels[test_y[id][0]] ))\n",
    "plt.imshow(test_x[id])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n, min_n = train_x.max(), train_x.min()\n",
    "\n",
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_n = len(np.unique(train_y))\n",
    "class_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, class_n)\n",
    "test_y = to_categorical(test_y, class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(32,32,3))\n",
    "fl = keras.layers.Flatten()(il)\n",
    "hl = keras.layers.Dense(521, activation='relu')(fl)\n",
    "hl = keras.layers.Dense(521, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(128, activation='relu')(hl)\n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = keras.callbacks.EarlyStopping(verbose=1\n",
    "                                    , patience=5\n",
    "                                    , restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, callbacks=[call],\n",
    "                    epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_test = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(history, dict):\n",
    "    history = history.history\n",
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "\n",
    "plt.title('Training vs Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(history.keys(), loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(train_x)\n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_test = pred_test.argmax(axis=1)\n",
    "\n",
    "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
    "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
    "\n",
    "\n",
    "print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))\n",
    "print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "\n",
    "print('id = {}'.format(id))\n",
    "print('다음 그림은 {} 입니다.'.format(labels[test_y.argmax(axis=1)[id]] ))\n",
    "print('모델의 예측 : {}'.format(labels[single_pred_test[id]] ))\n",
    "\n",
    "prob = np.floor(pred_test[id]*100).tolist()\n",
    "prob_dict = {}\n",
    "\n",
    "for idx, prob in enumerate(prob) :\n",
    "    prob_dict[ labels[idx] ] = prob\n",
    "\n",
    "print('모델의 카테고리별 확률 : ')\n",
    "print(prob_dict)\n",
    "\n",
    "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
    "    print('정답입니다')\n",
    "else : \n",
    "    print('틀렸어요')\n",
    "    \n",
    "plt.imshow(test_x[id].reshape([32,32,-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x, columns=iris.feature_names)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_l = x_train[['sepal length (cm)', 'petal length (cm)']]\n",
    "x_train_w = x_train[['sepal width (cm)', 'petal width (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_l = x_val[['sepal length (cm)', 'petal length (cm)']]\n",
    "x_val_w = x_val[['sepal width (cm)', 'petal width (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y = len(set(y))\n",
    "len_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, len_y)\n",
    "y_val = to_categorical(y_val, len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il_l = keras.layers.Input(shape=(2,))\n",
    "hl_l = keras.layers.Dense(2, activation='relu')(il_l)\n",
    "\n",
    "il_w = keras.layers.Input(shape=(2,))\n",
    "hl_w = keras.layers.Dense(2, activation='relu')(il_w)\n",
    "\n",
    "# 2개의 Input 연결\n",
    "cl = keras.layers.Concatenate()([hl_l, hl_w])\n",
    "ol = keras.layers.Dense(3, activation='softmax')(cl)\n",
    "\n",
    "model = keras.models.Model([il_l, il_w], ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5,\n",
    "                                    verbose=1,\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_train_l, x_train_w], y_train, validation_split=0.1,\n",
    "          epochs=1000, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([x_val_l, x_val_w], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([x_val_l, x_val_w])\n",
    "pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN ( Convolutional Neural Networks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "- param\n",
    "    - filters : depth. 필터 map 수\n",
    "    - kernel_size : 탐색 filter 사이즈\n",
    "    - strides : 간격\n",
    "    - padding : default valid. 사이드 0 추가(same)\n",
    "    - activation\n",
    "    - data_format, dilation_rate, groups, use_bias, kernel_initializer, bias_initializer, activity_regularizer, kernel_constraint, bias_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 1), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Airplane',\n",
       " 1: 'Automobile',\n",
       " 2: 'Bird',\n",
       " 3: 'Cat',\n",
       " 4: 'Deer',\n",
       " 5: 'Dog',\n",
       " 6: 'Frog',\n",
       " 7: 'Horse',\n",
       " 8: 'Ship',\n",
       " 9: 'Truck'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = { 0 : 'Airplane',\n",
    "          1 : 'Automobile',\n",
    "          2 : 'Bird',\n",
    "          3 : 'Cat',\n",
    "          4 : 'Deer',\n",
    "          5 : 'Dog',\n",
    "          6 : 'Frog',\n",
    "          7 : 'Horse',\n",
    "          8 : 'Ship',\n",
    "          9 : 'Truck' }\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671 Deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdU0lEQVR4nO2dW4xk13We/1WnTl27e3p6ZkiOhoxIEYRjgYgpYcAIUGAokWMwggFJDxKsB4MPgscPFhAB9gOhAJHypgSRDD0EAkYRYTpQZAmRBBEBkVggHBAGAlkjmaQo07YuYSiaYw45M32pe9WplYcuBkN6/6ub093VY+3/AxpddXbtc9bZZ686VfuvtZa5O4QQv/jUjtsAIcRykLMLkQlydiEyQc4uRCbI2YXIBDm7EJlQP0hnM3sIwBcAFAD+s7t/Nnp9p9X0E6vdZFutZrTffJ6WB+fzObct2F/NeJsFb3+snzvfn+PmpM1oPCL7nbx/8x5AreA28hEGqoq3VhXZZzBWFp1XIBHfzDywaERuUo6O5lxwamBTJDxnMvZbvQGGo3HyaDft7GZWAPhPAP4lgJcAfM/MHnf3v2R9Tqx28fCHfi3Z1l1p0GMNh5Pk9n5vRPu02nx/zSYf+Va7oG2NZnqf0yl/h5jNZrStVvB+rSZvawfn5lU7ub3gp4VWlzvLOHizur41pG297fQ1mwVjVTb4eU1n6f0BwGAwoG2NZjO9vc6nvk/5NXMPrlmb77Ms+Tg6ObUqmDvb2/3k9q88/qe0z0E+xj8I4Cfu/jN3nwD4YwAfPMD+hBBHyEGc/RyAn9/w/KXFNiHELchBnD31WfjvfVYxswtmdsnMLg1G4wMcTghxEA7i7C8BuOuG53cCePnNL3L3i+5+3t3Pd1rp709CiKPnIM7+PQD3mdk9ZtYA8JsAHj8cs4QQh81Nr8a7+8zMPgHgf2JXenvU3X+0Vz8mKY1GfGXd5+k+VRWsVm7xrwyRrLWykpYGAcAwTW4vgvfMSE4qghXhahD0Q4u27WxvJbevrfM+9SZfjZ/NAnltyK9ZRRSUnei6RJJBcFsaDrgq0Pf0eJSNkvYpavy6dNp8fswiCTNYWZ8O0/MqmqfjUXp854FcdyCd3d2fAPDEQfYhhFgO+gWdEJkgZxciE+TsQmSCnF2ITJCzC5EJB1qNf6u4OyaTtMzQbPH3nbmn5R8Poq4mRM4AAAOXeHpbaakGAMpa2saVFg/g6HTTgSkAAB7bgVEg1RQ1ft69HSZDccmr0eA/dpqz6DUARdCGaUX68C4g13l3d/x6tksuo/V76YCR8ZTvrxnIa42Sj1VV8Qvqc37iBZEcma8AwHicbnMSIQrozi5ENsjZhcgEObsQmSBnFyIT5OxCZMLSV+Nns/QqYsuCQA2yWjkL0gcVwYr7dMJXLId9vqI6J4Er7SBwYmI8WCRafQb4qm9/i6/SFjWyMl3x1eDZmNsRBYzUnNtRI0NcTfj4rqyt0bYWuB1VsNJdlWmlxIKUYM1Wh7ZNySo4ABSBN9XKYI4QZSBIrUfzMkY5D3VnFyIT5OxCZIKcXYhMkLMLkQlydiEyQc4uRCYsVXqbz+cYDtOBGpFssbqSlmTmMy4zbF/bCeyIyvRwiYfl/RqXfH+zaVCayLjEs7ayTttqwXv0cNhLbg/S3WEU5Lur1biEWQ92euLEieT2suBBJn0yN4C4wk9U3IoFhswCXcuDAJ9ZIGF2O/x69gc8wOr6tXSwTrMZVZhJt0U5D3VnFyIT5OxCZIKcXYhMkLMLkQlydiEyQc4uRCYcSHozsxcA7ACoAMzc/fwer6dyTbvNc7XVSY6xZoNHyo1G1/j+6lxeW13l0WbmaVmjbHJ5yoNEc2x/AIAgki4IbMKAlELyoCxQo7HK21pBDrp6JMulr2dZBmNFcvwBwBxc8rqZEltlUGpqHEQBjsZcHmw0uP2DHo9+3NlKt41b/LzaoRSZ5jB09n/u7q8dwn6EEEeIPsYLkQkHdXYH8Cdm9n0zu3AYBgkhjoaDfox/r7u/bGa3AfiOmf2Vuz914wsWbwIXAGClw79jCyGOlgPd2d395cX/KwC+BeDBxGsuuvt5dz/fbr71RQUhxOFw085uZl0zW339MYBfB/DcYRkmhDhcDvIx/nYA31rIHnUA/9Xd/0fUoSgKnFxPR0NFH/GdSFStNpfJWm0egeRBxFPZ4HLHSjctUdULLk9NeE5MzCsu/wzGXKrZfG2TtjUaaYmqFtk4DtpG/ARYWS4AKMmnuHlwf4mSW04nQfZF5/tsN9NRdpGUNxoPaNt4yMtoXa/4WPX6PAqzRpKt1gKNtUlKdtUCGfKmnd3dfwbgV262vxBiuUh6EyIT5OxCZIKcXYhMkLMLkQlydiEyYcm13uaYjol00eGyy4zUwhpP0skVAR7tBABmQSRXI5A72ul9RhKJ1bk8OB5xmeTqqzy26G9++gJt+6VfPpvc3g4yenpQK224HUheRRC1V6RlqFqQRHFc8YiySSBF1gs+xiA1/wYjPnc8qGHXaPJ5urnJk0pubW/StjMbb0tuP31qnfap19Nzrmb8/q07uxCZIGcXIhPk7EJkgpxdiEyQswuRCUsv/zTopYMMotxvtVp61bcR5H4r6vx9bHWNlyBaWQvyoM3Tq7RrpNQRAFRTfl5FEJBzdXqVtnVa/LJ1O+m27mqQL64ZBIX0eVu95OfWIOc2n/NAkgaPXcLc+FjV61GQTHpzGSgoHePnNW/zgK3pjCsGk4qHdzc76TnXWeUr//3+dnK7g4+F7uxCZIKcXYhMkLMLkQlydiEyQc4uRCbI2YXIhKVKb3CAVSEKUmeBVQWKyg+trHIdZ2UtKPFUcPlkTuSaejMwvuLvpz7hpaGaQUDDP7rjNtp2x+nTye3tNS6hzcEDP8a9IGio4HJSQeRSn/M8bRvrK7QNG1wurRdcojIyjrPBGu0z2eHy4GtbPIBmbZ2Px8bpc7St0SJztc6vyxSkzFcgKerOLkQmyNmFyAQ5uxCZIGcXIhPk7EJkgpxdiEzYU3ozs0cB/AaAK+5+/2LbBoCvAbgbwAsAPuru1/fa13zuGA7T0tZsxqWhRiNtpjFNDsDKCR6dtHKCn/as4nJHWaYlkkD5wTTI7zYa8JJAFuRBK8APONpJH68RlFZCLYgoMz5W9cCO0tP9mkGkYn0aSJhBYFtZBvkGiQTYDu5z2xWX3la6XF6rB1F7tWCu1sr0OE6mvAxVu5uWj9n5Avu7s/8hgIfetO0RAE+6+30Anlw8F0Lcwuzp7It669fetPmDAB5bPH4MwIcO1ywhxGFzs9/Zb3f3ywCw+M9/0iWEuCU48p/LmtkFABcAoNuK8nsLIY6Sm72zv2JmZwFg8f8Ke6G7X3T38+5+vhUtEgkhjpSbdfbHATy8ePwwgG8fjjlCiKNiP9LbVwG8D8BpM3sJwKcBfBbA183s4wBeBPCR/RzMDKgR5WVWcYkKk7ScYMZlHLdAymvzTxjNoJTQdEKSKIJHr11+7WXathmUBPKKn9tw0KZtnW46cmw64tFmq6t8GjQLLmFizCOsJlvpMbExP6/JhO+vCuyPkizOifTZKLgdc1K6CgAap/jcKRpcluuTRKsAQJW+QImMpEjGns7u7h8jTe9/64cTQhwX+gWdEJkgZxciE+TsQmSCnF2ITJCzC5EJS004WZZ1vO1t5Je1Uc7Gafo9qaqiLJVcxoHxiLJGkDySJS8s63wYT57hdeBOngoSLAaJKp9/5s2hCjd0q9LnXQ34eY2nXGoquoHk5YHk1U/bUQS10oo5t3Ey4HYMR33aVlVpCbAMEnq217mNxi8nnCtvGPS5jZNxOhJ0dY3Pj+FO+rycXH9Ad3YhskHOLkQmyNmFyAQ5uxCZIGcXIhPk7EJkwlKlNzNDUU/LK1evbtJ+K910/TIW4QUAZZu/j9WbvJ5b2QwSA5IouyKQcW4/x5P4WBBdFYU1Xb0WyFCvpWuRtQpeK60W2G9TLuWMRjwxY52EN86dy2tzi+RSbuM0SFY6GKYlr3Yt0MnIHAWA2oAfq9bgNlYVv55DkiR01OcS6+WX0ykkxmMegak7uxCZIGcXIhPk7EJkgpxdiEyQswuRCUtdjZ/P5xgP0yu43W6wWkzSfpVtvnrrBV8pngcruzNStggA5p4+3mzKV2jLZlR2KbA/WI2/697badtfb/2f5PY+FyCw1j0T2BHkhau4KlDNif2jIBfbLFqN5yvko0mwUj9PX8+izvuMR3yw1sY8/1+35Cv8Mx57hWEvPX9mM76yPuyldzifKxBGiOyRswuRCXJ2ITJBzi5EJsjZhcgEObsQmbCf8k+PAvgNAFfc/f7Fts8A+G0Ary5e9il3f2KvfVXVHFub6UAN1Hk5nlY3LSe01rhch6D8k8+4HDYJAhaMJMobD7muMpvz82p2+fC7cTs6a0HOu9s7ye0vPs/LUJ0+xROreZAXbjjl0pDV0jaOA2koyp/mQb/egMwpALN5WoKdIZgfgdy4MkuPLwCcOblB26ZjXlashbT9w+C81lbS+/uLF/+W9tnPnf0PATyU2P4H7v7A4m9PRxdCHC97Oru7PwWAx9oJIf5BcJDv7J8ws2fN7FEzO3loFgkhjoSbdfYvArgXwAMALgP4HHuhmV0ws0tmdmkYBNYLIY6Wm3J2d3/F3SvfrRLwJQAPBq+96O7n3f18uxlkBxFCHCk35exmdvaGpx8G8NzhmCOEOCr2I719FcD7AJw2s5cAfBrA+8zsAQAO4AUAv7PvI5KosuvXt2mXVSL/NJpc1lpZ5VLHcMijmqoqiGAjUU072zySqxlE5pXNdd7WCkoQBdFy//j+e5LbJ70h7XNtJ53PDADWAhvHUy4PTmZpyctYCCMAq/Oxj0p2TWv86+F2fyu5vTfk97lWk+c2nE2DHHqB+RsnV2nbapmexw4u8zFJ9InvPUv77Ons7v6xxOYv79VPCHFroV/QCZEJcnYhMkHOLkQmyNmFyAQ5uxCZsNSEk9Vsjk0isc2CBIvTCWmruAxSjYLEe84lu8L4kIwHafmnt81lrfGI21jUuQzVWeVtrRa3sb+TlpqKoM/119J9AGA24mM16HHJy4u0/TUiMwHAZMYl0blzebMIblmzWrqxtxOUAGus0baq4vb3dvg8iK51o56eq2UwVkbmaVELSlfRFiHELxRydiEyQc4uRCbI2YXIBDm7EJkgZxciE5YqvdVqhk4nXSvrlWtXab+N06eT27stHhXU29mkbd0u79ds8GizQT8trcxnXDbcHvKkgRWpHQcAjR1+aaK8AP3ttLRZK3gfB2+7vrlD23p9LodZK73POZHCAKA36tO26Yy3rXb4NWs30hFstTJIYNnn5zwc8uScwz6X18qSh8S1Oun5OJ/zSL/JWLXehBAEObsQmSBnFyIT5OxCZIKcXYhMWOpqfL2s4/SZU+nGkr/vNJppMy340X93lZeGMuP94re/9ErncMBXivtDvgo7mfLV1o1T67StXaQVDQCYkVXabpMrEPU6X43fmQYBKE0+WFuT68ntE/BzHs/4WK2u8BX3u95+G227ejm9sn5yI8gzN+FBMpNJOrceAJQFL5/QKHlOxP5wltxuQQmwAQnK0mq8EELOLkQuyNmFyAQ5uxCZIGcXIhPk7EJkwn7KP90F4I8A3AFgDuCiu3/BzDYAfA3A3dgtAfVRd0/rLf8fhyMtM9x2O5HkAFhBcnEVXGYogsRks1naBgCYzXlbs5UOdFg/wUv7bG29QttOnOBBFatdLh1uBLJiiXTboMflwXrBJa9GO8iFt8LtuOfOO5PbO6e4BOXgkuhtGzwv3MlAlvvzp54hfda5HXxaoTcIpDdSHmwXfm6TKp3LL0hbByfT229WVV4wA/B77v7LAN4D4HfN7J0AHgHwpLvfB+DJxXMhxC3Kns7u7pfd/QeLxzsAngdwDsAHATy2eNljAD50RDYKIQ6Bt/Sd3czuBvAuAN8FcLu7XwZ23xAA8J8xCSGOnX07u5mtAPgGgE+6O6+v/Pf7XTCzS2Z2aTDiecaFEEfLvpzdzErsOvpX3P2bi82vmNnZRftZAMki3+5+0d3Pu/v5DsleIoQ4evZ0dtuNGvkygOfd/fM3ND0O4OHF44cBfPvwzRNCHBb7iXp7L4DfAvBDM3t6se1TAD4L4Otm9nEALwL4yF47cndUFYl64ooXjOgJc+eSS5S/a0qkDgAogui7zko6cqwM8rtNp1zHWV/nUVLrJFcfANSdD9bJlXS/+YhHcp0+yY+FKS9BNK/zqKzz//T+5PbOKb6/quISYL3Gj2XBtb7zrrSkWxqXAFdP8uvy4x+/QNt6A17+aW2dy6x1Oo78OteRHscoonNPZ3f3PwMXCd+/V38hxK2BfkEnRCbI2YXIBDm7EJkgZxciE+TsQmTCUhNOAoATlWHY49JQjUS31ev8varV5SFDRcllnHogvY1HaYlnOuWRUPe+4xxt69a5/DMNfm042uHHWyUy2j3neNTYjOeUxGT8c9o2qLg01CKnZs7PazbhElrV4JJSUfBpvHpiI7l988oW7bMezJ1Td3JZbmfK53DpPOEn2LnxaQqvkz4HjHoTQvwCIGcXIhPk7EJkgpxdiEyQswuRCXJ2ITJhydKboWZpWaO3zfWfWi0tvZVM3wGwus6TIdZLftpzHniFGom8agZx+u02b6tVXFspmbQCoH2KR1CVnfS5bazxPv3rfOzP3MH7bY+4BAhLy3KTMe8zIvXLAIAFSwJAUfB5YLX0eHhQJ7A34eNx8nQwHltczpsGNeIKkqiyCGwMSrpRdGcXIhPk7EJkgpxdiEyQswuRCXJ2ITJhqavx7o7xOL2sev1aj/Yry/QKfqPLgyo2Kr5cOQ0iDIoaf/9bI2WXgtgDWLBsGpWoOnGCB64UQUkmJ/nMqhoPWhkbz5124lSQEbjHz208Tq9oR3aArJwDCGsyzcZ8nyyvXXeNB6aULZ4nL7o7NoL8b9WQz1UnhyuD67wzSPvLfM7ntu7sQmSCnF2ITJCzC5EJcnYhMkHOLkQmyNmFyIQ9pTczuwvAHwG4A7tZsS66+xfM7DMAfhvAq4uXfsrdn4j2Vc0qbG2mgwWuXeNBBGur6eCDmnHzh0MeOWGB/NNs8X222+mAizLIgXbt1ddoW7fJyy6tra/StlkRnBvJr1dZUMapEYzHnMtJJ5srtI3l8tsJcg0WDR68hCAoxJzfs2YzInmRvIZAnIewInkIAcCDwCYLAqx8mu5Xa3M75kRaDhTKfensMwC/5+4/MLNVAN83s+8s2v7A3f/jPvYhhDhm9lPr7TKAy4vHO2b2PACeMlUIcUvylr6zm9ndAN4F4LuLTZ8ws2fN7FEz4zl2hRDHzr6d3cxWAHwDwCfdfRvAFwHcC+AB7N75P0f6XTCzS2Z2aTQNfiophDhS9uXsZlZi19G/4u7fBAB3f8XdK3efA/gSgAdTfd39orufd/fzrSBDjBDiaNnT2W23uvuXATzv7p+/YfvZG172YQDPHb55QojDYj+32vcC+C0APzSzpxfbPgXgY2b2AAAH8AKA39lrR+6O8SQdYVUGckernTazbPCooMmYax3VPJBPnH/VWF1ppe2o88iw8ZRHlEXnPCf57gDASi5DeT2tvdSCnHadVS4Bgqd3w7Ticl6jkT632YyP79S5LFf3IJcfDygDC2IsA4mVpDwEAEyJTAYAXvHr2SiDgSSXZhJEygXBbZT9rMb/GTEn1NSFELcW+gWdEJkgZxciE+TsQmSCnF2ITJCzC5EJS/2VixnQaKblmnN3nqL9mq20xDYNZC0fczlpe3uTtjX6XBpaW0vLPydP8Oivt999F20r61w6LIOyUWMPyi4hrRtVQV2rWpD4ch6k07Rg+rDEh80mPy9r8GtWq/GxmgYRju7kvJ2fVy2Q0HpbvDTUYJtflyaJRgSA7on0uUXJSusk0tKCpJe6swuRCXJ2ITJBzi5EJsjZhcgEObsQmSBnFyITliq9NVoN3HPvncm2ouDSSq1IyxakbBwA4NWrvHbcbMplqGaLyx3VPC3LVRWX69qddKTcXszBbRyNeHRYSZJwunHpZ9rn0VVbr3J5s91Zp20NFn0X1NKrnNs46nM7msblvGYrHW1W8IA99Df53Nm+ztuuX+eyXLPBZblaPZ1os7PGI+UKmuRU0psQ2SNnFyIT5OxCZIKcXYhMkLMLkQlydiEyYanSW71ew/oZEiEWJPmbkySQQckznKrxSLTbarymWLsbJQ1MD9dmIMd0ulxC65IElgBQ1rkd9ZLrRqzW12DIpZ/xOIjWCpJRzoJMj9u9neT2Tieo5xbUQ3vlpb+jbWuNNd52Ii1fVRWfPFvXt2nbLEhkGmWBHI76tG27TyIVg6SjjRaZO0GxN93ZhcgEObsQmSBnFyIT5OxCZIKcXYhM2HM13sxaAJ7CbiGgOoD/5u6fNrMNAF8DcDd2yz991N2v77EvlM30IccTvrI7IREv7Q5fce+sdGhbkHINRVBaqb+TXlHd2eYrrfMgj1jNeFtR5/Y3g7JXNRLhMe4HeeuMD8jq+ipt60+5CjHtpRUUCyJQJoGNO9c2aVtvukXbKjud3N7u8CCTZpurJEWNB900gvx6BZn3AMB2OZnxlf+iSq/UB6LWvu7sYwD/wt1/BbvlmR8ys/cAeATAk+5+H4AnF8+FELcoezq77/L6W3i5+HMAHwTw2GL7YwA+dBQGCiEOh/3WZy8WFVyvAPiOu38XwO3ufhkAFv9vOzIrhRAHZl/O7u6Vuz8A4E4AD5rZ/fs9gJldMLNLZnap1+dJF4QQR8tbWo13900A/wvAQwBeMbOzALD4f4X0ueju5939/Er35rK2CCEOzp7ObmZnzGx98bgN4NcA/BWAxwE8vHjZwwC+fUQ2CiEOgf0EwpwF8JiZFdh9c/i6u/93M/vfAL5uZh8H8CKAj+y9KwNIjrTxmOcYGw7SslytxoMZOl1+albj8tpoGJT3GaRtnAUSySSQFHd6vJ8VgSzX4OfWaqUDVyyI33Ai4wCx/a0OD5I5Rcp8zcb8WONxcCxyXgBQgc+DCdlnq8ult+46lz3rRZDvLsiTNx7xcxsM09JtlNvQScDLPCjztaezu/uzAN6V2H4VwPv36i+EuDXQL+iEyAQ5uxCZIGcXIhPk7EJkgpxdiEwwtoR/JAczexXA/108PQ3gtaUdnCM73ojseCP/0Ox4u7ufSTUs1dnfcGCzS+5+/lgOLjtkR4Z26GO8EJkgZxciE47T2S8e47FvRHa8EdnxRn5h7Di27+xCiOWij/FCZMKxOLuZPWRmf21mPzGzY8tdZ2YvmNkPzexpM7u0xOM+amZXzOy5G7ZtmNl3zOzHi/8nj8mOz5jZ3y7G5Gkz+8AS7LjLzP7UzJ43sx+Z2b9ebF/qmAR2LHVMzKxlZn9uZs8s7Ph3i+0HGw93X+ofgALATwG8A0ADwDMA3rlsOxa2vADg9DEc91cBvBvAczds+w8AHlk8fgTAvz8mOz4D4PeXPB5nAbx78XgVwN8AeOeyxySwY6ljAsAArCwelwC+C+A9Bx2P47izPwjgJ+7+M3efAPhj7CavzAZ3fwrAtTdtXnoCT2LH0nH3y+7+g8XjHQDPAziHJY9JYMdS8V0OPcnrcTj7OQA/v+H5SziGAV3gAP7EzL5vZheOyYbXuZUSeH7CzJ5dfMw/8q8TN2Jmd2M3f8KxJjV9kx3AksfkKJK8Hoezp9LEHJck8F53fzeAfwXgd83sV4/JjluJLwK4F7s1Ai4D+NyyDmxmKwC+AeCT7s7rJi/fjqWPiR8gySvjOJz9JQB33fD8TgAvH4MdcPeXF/+vAPgWdr9iHBf7SuB51Lj7K4uJNgfwJSxpTMysxK6DfcXdv7nYvPQxSdlxXGOyOPYm3mKSV8ZxOPv3ANxnZveYWQPAb2I3eeVSMbOuma2+/hjArwN4Lu51pNwSCTxfn0wLPowljImZGYAvA3je3T9/Q9NSx4TZsewxObIkr8taYXzTauMHsLvS+VMA/+aYbHgHdpWAZwD8aJl2APgqdj8OTrH7SefjAE5ht4zWjxf/N47Jjv8C4IcAnl1MrrNLsOOfYfer3LMAnl78fWDZYxLYsdQxAfBPAPzF4njPAfi3i+0HGg/9gk6ITNAv6ITIBDm7EJkgZxciE+TsQmSCnF2ITJCzC5EJcnYhMkHOLkQm/D9QXO47YK18VAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = rd.randrange(0,10000)\n",
    "\n",
    "print(idx, labels[test_y[idx][0]])\n",
    "plt.imshow(test_x[idx])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_x, min_x = train_x.max(), train_x.min()\n",
    "max_x, min_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / max_x\n",
    "test_x = test_x / max_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Y One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_y.reshape(train_y.shape[0])\n",
    "test_y = test_y.reshape(test_y.shape[0])\n",
    "\n",
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y = len(set(train_y))\n",
    "\n",
    "train_y = to_categorical(train_y, len_y)\n",
    "test_y = to_categorical(test_y, len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLearning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Applies Dropout to the input.\n",
      "\n",
      "The Dropout layer randomly sets input units to 0 with a frequency of `rate`\n",
      "at each step during training time, which helps prevent overfitting.\n",
      "Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\n",
      "all inputs is unchanged.\n",
      "\n",
      "Note that the Dropout layer only applies when `training` is set to True\n",
      "such that no values are dropped during inference. When using `model.fit`,\n",
      "`training` will be appropriately set to True automatically, and in other\n",
      "contexts, you can set the kwarg explicitly to True when calling the layer.\n",
      "\n",
      "(This is in contrast to setting `trainable=False` for a Dropout layer.\n",
      "`trainable` does not affect the layer's behavior, as Dropout does\n",
      "not have any variables/weights that can be frozen during training.)\n",
      "\n",
      ">>> tf.random.set_seed(0)\n",
      ">>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
      ">>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n",
      ">>> print(data)\n",
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]\n",
      " [6. 7.]\n",
      " [8. 9.]]\n",
      ">>> outputs = layer(data, training=True)\n",
      ">>> print(outputs)\n",
      "tf.Tensor(\n",
      "[[ 0.    1.25]\n",
      " [ 2.5   3.75]\n",
      " [ 5.    6.25]\n",
      " [ 7.5   8.75]\n",
      " [10.    0.  ]], shape=(5, 2), dtype=float32)\n",
      "\n",
      "Args:\n",
      "  rate: Float between 0 and 1. Fraction of the input units to drop.\n",
      "  noise_shape: 1D integer tensor representing the shape of the\n",
      "    binary dropout mask that will be multiplied with the input.\n",
      "    For instance, if your inputs have shape\n",
      "    `(batch_size, timesteps, features)` and\n",
      "    you want the dropout mask to be the same for all timesteps,\n",
      "    you can use `noise_shape=(batch_size, 1, features)`.\n",
      "  seed: A Python integer to use as random seed.\n",
      "\n",
      "Call arguments:\n",
      "  inputs: Input tensor (of any rank).\n",
      "  training: Python boolean indicating whether the layer should behave in\n",
      "    training mode (adding dropout) or in inference mode (doing nothing).\n",
      "\u001b[1;31mInit docstring:\u001b[0m\n",
      "Initialize the BaseRandomLayer.\n",
      "\n",
      "Note that the constructor is annotated with\n",
      "@no_automatic_dependency_tracking. This is to skip the auto\n",
      "tracking of self._random_generator instance, which is an AutoTrackable.\n",
      "The backend.RandomGenerator could contain a tf.random.Generator instance\n",
      "which will have tf.Variable as the internal state. We want to avoid\n",
      "saving that state into model.weights and checkpoints for backward\n",
      "compatibility reason. In the meantime, we still need to make them\n",
      "visible to SavedModel when it is tracing the tf.function for the\n",
      "`call()`.\n",
      "See _list_extra_dependencies_for_serialization below for more details.\n",
      "\n",
      "Args:\n",
      "  seed: optional integer, used to create RandomGenerator.\n",
      "  force_generator: boolean, default to False, whether to force the\n",
      "    RandomGenerator to use the code branch of tf.random.Generator.\n",
      "  rng_type: string, the rng type that will be passed to backend\n",
      "    RandomGenerator. Default to `None`, which will allow RandomGenerator\n",
      "    to choose types by itself. Valid values are \"stateful\", \"stateless\",\n",
      "    \"legacy_stateful\".\n",
      "  **kwargs: other keyword arguments that will be passed to the parent\n",
      "    *class\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\mskyu\\anaconda3\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, Dropout\n"
     ]
    }
   ],
   "source": [
    "Dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,249,738\n",
      "Trainable params: 4,248,394\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Input\n",
    "model.add(Input((32,32,3)))\n",
    "\n",
    "model.add(Conv2D(filters=32,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# output\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbaseline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Stop training when a monitored metric has stopped improving.\n",
      "\n",
      "Assuming the goal of a training is to minimize the loss. With this, the\n",
      "metric to be monitored would be `'loss'`, and mode would be `'min'`. A\n",
      "`model.fit()` training loop will check at end of every epoch whether\n",
      "the loss is no longer decreasing, considering the `min_delta` and\n",
      "`patience` if applicable. Once it's found no longer decreasing,\n",
      "`model.stop_training` is marked True and the training terminates.\n",
      "\n",
      "The quantity to be monitored needs to be available in `logs` dict.\n",
      "To make it so, pass the loss or metrics at `model.compile()`.\n",
      "\n",
      "Args:\n",
      "  monitor: Quantity to be monitored.\n",
      "  min_delta: Minimum change in the monitored quantity\n",
      "      to qualify as an improvement, i.e. an absolute\n",
      "      change of less than min_delta, will count as no\n",
      "      improvement.\n",
      "  patience: Number of epochs with no improvement\n",
      "      after which training will be stopped.\n",
      "  verbose: Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1\n",
      "      displays messages when the callback takes an action.\n",
      "  mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
      "      training will stop when the quantity\n",
      "      monitored has stopped decreasing; in `\"max\"`\n",
      "      mode it will stop when the quantity\n",
      "      monitored has stopped increasing; in `\"auto\"`\n",
      "      mode, the direction is automatically inferred\n",
      "      from the name of the monitored quantity.\n",
      "  baseline: Baseline value for the monitored quantity.\n",
      "      Training will stop if the model doesn't show improvement over the\n",
      "      baseline.\n",
      "  restore_best_weights: Whether to restore model weights from\n",
      "      the epoch with the best value of the monitored quantity.\n",
      "      If False, the model weights obtained at the last step of\n",
      "      training are used. An epoch will be restored regardless\n",
      "      of the performance relative to the `baseline`. If no epoch\n",
      "      improves on `baseline`, training will run for `patience`\n",
      "      epochs and restore weights from the best epoch in that set.\n",
      "\n",
      "Example:\n",
      "\n",
      ">>> callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
      ">>> # This callback will stop the training when there is no improvement in\n",
      ">>> # the loss for three consecutive epochs.\n",
      ">>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
      ">>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n",
      ">>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
      "...                     epochs=10, batch_size=1, callbacks=[callback],\n",
      "...                     verbose=0)\n",
      ">>> len(history.history['loss'])  # Only 4 epochs are run.\n",
      "4\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\mskyu\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "keras.callbacks.EarlyStopping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs=500, verbose=1, validation_split=.2, callbacks=[es], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f7678e3cf7566e35dc0bd53f9a2e61d18c90ac4f700ab60c30179035bddd9e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
