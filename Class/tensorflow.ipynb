{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning ( TensorFlow )\n",
    "* https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netural Network\n",
    "- features(x) -> neuron -> target(y)\n",
    "    - ex) 주택 가격  \n",
    "    features(크기, 위치, 형태, ..) -> neuron(가중치, 그래프, 관계) -> target(가격)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,20))\n",
    "y = x * 2 - 1\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kears 모델 클리어\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# keras 모델 선언\n",
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 노드 조립\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# 컴파일\n",
    "# loss : 예측값 평가 기준 \n",
    "# optimizer : \n",
    "model.compile(loss='mse'\n",
    "              , optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs : 학습 횟수\n",
    "# verbose : 학습 과정 표현\n",
    "model.fit(x,y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,40)) \n",
    "y = np.array([0, 1] * 20)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy'\n",
    "              , optimizer='adam'\n",
    "              , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = x * 2 -1\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "\n",
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN / MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "# id = 0\n",
    "\n",
    "print(f'id = {id}')\n",
    "print(f'다음 그림은 숫자 {y_train[id]} 입니다.')\n",
    "\n",
    "plt.imshow(x_train[id])\n",
    "plt.show()\n",
    "\n",
    "# print(x_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[0], x_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3차원 -> 2차원\n",
    "x_train = x_train.reshape([x_train.shape[0],-1])\n",
    "x_val = x_val.reshape([x_val.shape[0],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'max : {x_train.max()} / min : {x_train.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n, min_n = x_train.max(), x_train.min()\n",
    "\n",
    "max_n, min_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train[0] - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - min_n) / (max_n - min_n)\n",
    "x_val = (x_val - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Sequential API\n",
    "# # 1. 세션 클리어\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# # 2. 모델 선언 : Sequential()\n",
    "# model = keras.models.Sequential()\n",
    "\n",
    "# # 3. 레이어 조립 : .add()\n",
    "# model.add( keras.layers.Input(shape=(784,)) )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add(keras.layers.Dense(256, activation='relu') )\n",
    "# model.add( keras.layers.Dense(10, activation='softmax') )\n",
    "\n",
    "# # 4. 컴파일\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "#               optimizer=keras.optimizers.Adam(0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functional API\n",
    "# 1. 세션 클리어\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 2. 레이어 사슬처럼 엮기\n",
    "il = keras.layers.Input(shape=(784,))\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "hl = keras.layers.Dense(256, activation='relu')\n",
    "ol = keras.layers.Dense(10, activation='softmax')(il)\n",
    "\n",
    "# 3. 모델의 시작과 끝 지정\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "# 4. 컴파일\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.Adam(0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', # 관측 대상\n",
    "                   min_delta=0,        # 최소한 나빠지지 않으면 괜찮아\n",
    "                   patience=5,         # 성능 개선되지 않는 걸 얼마나 참을래?\n",
    "                   verbose=1,\n",
    "                   restore_best_weights=True # 학습이 멈췄을 때, 최적의 가중치로 전환해줌\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=50, verbose=1,\n",
    "          validation_split=0.2,    # Train data의 20%를 Validation data로!\n",
    "          callbacks=[es]           # Early Stopping 적용\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x_train)\n",
    "pred_val = model.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train.shape, pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_val = pred_val.argmax(axis=1)\n",
    "single_pred_train.shape, single_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_train_accuracy = accuracy_score(y_train.argmax(axis=1), single_pred_train)\n",
    "logi_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_test_accuracy = accuracy_score(y_val.argmax(axis=1), single_pred_val)\n",
    "logi_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i, index in enumerate(np.random.choice(x_val.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1)\n",
    "    # Display each image\n",
    "    ax.imshow(x_val[index].reshape([28,-1]), cmap='gray' )\n",
    "    \n",
    "    predict_index = pred_val[index].argmax(axis=0)\n",
    "    true_index = y_val[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(f\"{mnist_labels[predict_index]} ({mnist_labels[true_index]})\",\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) 3차원 array 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.array(\n",
    "    [\n",
    "        [\n",
    "                       [0, 0],\n",
    "                       [2,-1],\n",
    "                       [1, 0],\n",
    "                       [2, 2],\n",
    "        ],\n",
    "        [\n",
    "                       [1, 1],\n",
    "                       [3, 3],\n",
    "                       [2,-1],\n",
    "                       [1, 1],\n",
    "        ],\n",
    "        [\n",
    "                       [2, 2],\n",
    "                       [7,-1],\n",
    "                       [8, 1],\n",
    "                       [1, 0],\n",
    "        ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample   = n1.shape[0] # 3 (3개 샘플 데이터)\n",
    "num_sequence = n1.shape[1] # 4 (4개 시계열 데이터)\n",
    "num_feature  = n1.shape[2] # 2 (2개 Feature(미세먼지, 초미세먼지 증감))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열을 선회하면서 피팅합니다\n",
    "for ss in range(num_sequence):\n",
    "    print('ss', ss)\n",
    "    print(n1[:, ss, :])\n",
    "    print()\n",
    "    scaler.partial_fit(n1[:, ss, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링(변환)합니다.\n",
    "results = []\n",
    "for ss in range(num_sequence):\n",
    "    results.append(scaler.transform(n1[:, ss, :]).reshape(num_sample, 1, num_feature))\n",
    "\n",
    "print(results)\n",
    "print()\n",
    "\n",
    "n1_scaled = np.concatenate(results, axis=1)\n",
    "print(n1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) tensorflow GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://afsdzvcx123.tistory.com/entry/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-Windows%EC%9C%88%EB%8F%84%EC%9A%B0-CUDA-cuDNN-%EC%84%A4%EC%B9%98%EB%B0%A9%EB%B2%95\n",
    "* https://doitgrow.com/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13427346610800829377\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254700544\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7411534314026108379\n",
      "physical_device_desc: \"device: 0, name: Quadro T1000 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# GPU 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gpu 사용\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu 사용\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 0 : 'Airplane',\n",
    "          1 : 'Automobile',\n",
    "          2 : 'Bird',\n",
    "          3 : 'Cat',\n",
    "          4 : 'Deer',\n",
    "          5 : 'Dog',\n",
    "          6 : 'Frog',\n",
    "          7 : 'Horse',\n",
    "          8 : 'Ship',\n",
    "          9 : 'Truck' }\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "\n",
    "print('id = {}'.format(id))\n",
    "print('다음 그림은 {} 입니다.'.format( labels[test_y[id][0]] ))\n",
    "plt.imshow(test_x[id])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n, min_n = train_x.max(), train_x.min()\n",
    "\n",
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_n = len(np.unique(train_y))\n",
    "class_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, class_n)\n",
    "test_y = to_categorical(test_y, class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(32,32,3))\n",
    "fl = keras.layers.Flatten()(il)\n",
    "hl = keras.layers.Dense(521, activation='relu')(fl)\n",
    "hl = keras.layers.Dense(521, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(128, activation='relu')(hl)\n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = keras.callbacks.EarlyStopping(verbose=1\n",
    "                                    , patience=5\n",
    "                                    , restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, validation_split=0.2, callbacks=[call],\n",
    "                    epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_test = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(history, dict):\n",
    "    history = history.history\n",
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "\n",
    "plt.title('Training vs Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(history.keys(), loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(train_x)\n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_test = pred_test.argmax(axis=1)\n",
    "\n",
    "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
    "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
    "\n",
    "\n",
    "print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))\n",
    "print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = rd.randrange(0,10000)\n",
    "\n",
    "print('id = {}'.format(id))\n",
    "print('다음 그림은 {} 입니다.'.format(labels[test_y.argmax(axis=1)[id]] ))\n",
    "print('모델의 예측 : {}'.format(labels[single_pred_test[id]] ))\n",
    "\n",
    "prob = np.floor(pred_test[id]*100).tolist()\n",
    "prob_dict = {}\n",
    "\n",
    "for idx, prob in enumerate(prob) :\n",
    "    prob_dict[ labels[idx] ] = prob\n",
    "\n",
    "print('모델의 카테고리별 확률 : ')\n",
    "print(prob_dict)\n",
    "\n",
    "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
    "    print('정답입니다')\n",
    "else : \n",
    "    print('틀렸어요')\n",
    "    \n",
    "plt.imshow(test_x[id].reshape([32,32,-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x, columns=iris.feature_names)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_l = x_train[['sepal length (cm)', 'petal length (cm)']]\n",
    "x_train_w = x_train[['sepal width (cm)', 'petal width (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_l = x_val[['sepal length (cm)', 'petal length (cm)']]\n",
    "x_val_w = x_val[['sepal width (cm)', 'petal width (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y = len(set(y))\n",
    "len_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, len_y)\n",
    "y_val = to_categorical(y_val, len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il_l = keras.layers.Input(shape=(2,))\n",
    "hl_l = keras.layers.Dense(2, activation='relu')(il_l)\n",
    "\n",
    "il_w = keras.layers.Input(shape=(2,))\n",
    "hl_w = keras.layers.Dense(2, activation='relu')(il_w)\n",
    "\n",
    "# 2개의 Input 연결\n",
    "cl = keras.layers.Concatenate()([hl_l, hl_w])\n",
    "ol = keras.layers.Dense(3, activation='softmax')(cl)\n",
    "\n",
    "model = keras.models.Model([il_l, il_w], ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5,\n",
    "                                    verbose=1,\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_train_l, x_train_w], y_train, validation_split=0.1,\n",
    "          epochs=1000, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([x_val_l, x_val_w], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([x_val_l, x_val_w])\n",
    "pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN ( Convolutional Neural Networks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "- param\n",
    "    - filters : depth. 필터 map 수\n",
    "    - kernel_size : 탐색 filter 사이즈\n",
    "    - strides : 간격\n",
    "    - padding : default valid. 사이드 0 추가(same)\n",
    "    - activation\n",
    "    - data_format, dilation_rate, groups, use_bias, kernel_initializer, bias_initializer, activity_regularizer, kernel_constraint, bias_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 1), (10000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Airplane',\n",
       " 1: 'Automobile',\n",
       " 2: 'Bird',\n",
       " 3: 'Cat',\n",
       " 4: 'Deer',\n",
       " 5: 'Dog',\n",
       " 6: 'Frog',\n",
       " 7: 'Horse',\n",
       " 8: 'Ship',\n",
       " 9: 'Truck'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = { 0 : 'Airplane',\n",
    "          1 : 'Automobile',\n",
    "          2 : 'Bird',\n",
    "          3 : 'Cat',\n",
    "          4 : 'Deer',\n",
    "          5 : 'Dog',\n",
    "          6 : 'Frog',\n",
    "          7 : 'Horse',\n",
    "          8 : 'Ship',\n",
    "          9 : 'Truck' }\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9147 Truck\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = rd.randrange(0,10000)\n",
    "\n",
    "print(idx, labels[test_y[idx][0]])\n",
    "plt.imshow(test_x[idx])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_x, min_x = train_x.max(), train_x.min()\n",
    "max_x, min_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / max_x\n",
    "test_x = test_x / max_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Y One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_y.reshape(train_y.shape[0])\n",
    "test_y = test_y.reshape(test_y.shape[0])\n",
    "\n",
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y = len(set(train_y))\n",
    "\n",
    "train_y = to_categorical(train_y, len_y)\n",
    "test_y = to_categorical(test_y, len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLearning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Applies Dropout to the input.\n",
      "\n",
      "The Dropout layer randomly sets input units to 0 with a frequency of `rate`\n",
      "at each step during training time, which helps prevent overfitting.\n",
      "Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\n",
      "all inputs is unchanged.\n",
      "\n",
      "Note that the Dropout layer only applies when `training` is set to True\n",
      "such that no values are dropped during inference. When using `model.fit`,\n",
      "`training` will be appropriately set to True automatically, and in other\n",
      "contexts, you can set the kwarg explicitly to True when calling the layer.\n",
      "\n",
      "(This is in contrast to setting `trainable=False` for a Dropout layer.\n",
      "`trainable` does not affect the layer's behavior, as Dropout does\n",
      "not have any variables/weights that can be frozen during training.)\n",
      "\n",
      ">>> tf.random.set_seed(0)\n",
      ">>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
      ">>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n",
      ">>> print(data)\n",
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]\n",
      " [6. 7.]\n",
      " [8. 9.]]\n",
      ">>> outputs = layer(data, training=True)\n",
      ">>> print(outputs)\n",
      "tf.Tensor(\n",
      "[[ 0.    1.25]\n",
      " [ 2.5   3.75]\n",
      " [ 5.    6.25]\n",
      " [ 7.5   8.75]\n",
      " [10.    0.  ]], shape=(5, 2), dtype=float32)\n",
      "\n",
      "Args:\n",
      "  rate: Float between 0 and 1. Fraction of the input units to drop.\n",
      "  noise_shape: 1D integer tensor representing the shape of the\n",
      "    binary dropout mask that will be multiplied with the input.\n",
      "    For instance, if your inputs have shape\n",
      "    `(batch_size, timesteps, features)` and\n",
      "    you want the dropout mask to be the same for all timesteps,\n",
      "    you can use `noise_shape=(batch_size, 1, features)`.\n",
      "  seed: A Python integer to use as random seed.\n",
      "\n",
      "Call arguments:\n",
      "  inputs: Input tensor (of any rank).\n",
      "  training: Python boolean indicating whether the layer should behave in\n",
      "    training mode (adding dropout) or in inference mode (doing nothing).\n",
      "\u001b[1;31mInit docstring:\u001b[0m\n",
      "Initialize the BaseRandomLayer.\n",
      "\n",
      "Note that the constructor is annotated with\n",
      "@no_automatic_dependency_tracking. This is to skip the auto\n",
      "tracking of self._random_generator instance, which is an AutoTrackable.\n",
      "The backend.RandomGenerator could contain a tf.random.Generator instance\n",
      "which will have tf.Variable as the internal state. We want to avoid\n",
      "saving that state into model.weights and checkpoints for backward\n",
      "compatibility reason. In the meantime, we still need to make them\n",
      "visible to SavedModel when it is tracing the tf.function for the\n",
      "`call()`.\n",
      "See _list_extra_dependencies_for_serialization below for more details.\n",
      "\n",
      "Args:\n",
      "  seed: optional integer, used to create RandomGenerator.\n",
      "  force_generator: boolean, default to False, whether to force the\n",
      "    RandomGenerator to use the code branch of tf.random.Generator.\n",
      "  rng_type: string, the rng type that will be passed to backend\n",
      "    RandomGenerator. Default to `None`, which will allow RandomGenerator\n",
      "    to choose types by itself. Valid values are \"stateful\", \"stateless\",\n",
      "    \"legacy_stateful\".\n",
      "  **kwargs: other keyword arguments that will be passed to the parent\n",
      "    *class\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\mskyu\\anaconda3\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, Dropout\n"
     ]
    }
   ],
   "source": [
    "Dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 65536)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               33554944  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,564,170\n",
      "Trainable params: 33,563,018\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Input\n",
    "model.add(Input((32,32,3)))\n",
    "\n",
    "# model.add(Conv2D(filters=32,\n",
    "#                 kernel_size=(3,3),\n",
    "#                 strides=(1, 1),\n",
    "#                 padding='same',\n",
    "#                 data_format=None,\n",
    "#                 dilation_rate=(1, 1),\n",
    "#                 groups=1,\n",
    "#                 activation='relu',\n",
    "#                 use_bias=True,\n",
    "#                 kernel_initializer='glorot_uniform',\n",
    "#                 bias_initializer='zeros',\n",
    "#                 kernel_regularizer=None,\n",
    "#                 bias_regularizer=None,\n",
    "#                 activity_regularizer=None,\n",
    "#                 kernel_constraint=None,\n",
    "#                 bias_constraint=None))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(filters=32,\n",
    "#                 kernel_size=(3,3),\n",
    "#                 strides=(1, 1),\n",
    "#                 padding='same',\n",
    "#                 data_format=None,\n",
    "#                 dilation_rate=(1, 1),\n",
    "#                 groups=1,\n",
    "#                 activation='relu',\n",
    "#                 use_bias=True,\n",
    "#                 kernel_initializer='glorot_uniform',\n",
    "#                 bias_initializer='zeros',\n",
    "#                 kernel_regularizer=None,\n",
    "#                 bias_regularizer=None,\n",
    "#                 activity_regularizer=None,\n",
    "#                 kernel_constraint=None,\n",
    "#                 bias_constraint=None))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(MaxPool2D((2,2)))\n",
    "\n",
    "# model.add(Conv2D(filters=64,\n",
    "#                 kernel_size=(3,3),\n",
    "#                 strides=(1, 1),\n",
    "#                 padding='same',\n",
    "#                 data_format=None,\n",
    "#                 dilation_rate=(1, 1),\n",
    "#                 groups=1,\n",
    "#                 activation='relu',\n",
    "#                 use_bias=True,\n",
    "#                 kernel_initializer='glorot_uniform',\n",
    "#                 bias_initializer='zeros',\n",
    "#                 kernel_regularizer=None,\n",
    "#                 bias_regularizer=None,\n",
    "#                 activity_regularizer=None,\n",
    "#                 kernel_constraint=None,\n",
    "#                 bias_constraint=None))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# output\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbaseline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Stop training when a monitored metric has stopped improving.\n",
      "\n",
      "Assuming the goal of a training is to minimize the loss. With this, the\n",
      "metric to be monitored would be `'loss'`, and mode would be `'min'`. A\n",
      "`model.fit()` training loop will check at end of every epoch whether\n",
      "the loss is no longer decreasing, considering the `min_delta` and\n",
      "`patience` if applicable. Once it's found no longer decreasing,\n",
      "`model.stop_training` is marked True and the training terminates.\n",
      "\n",
      "The quantity to be monitored needs to be available in `logs` dict.\n",
      "To make it so, pass the loss or metrics at `model.compile()`.\n",
      "\n",
      "Args:\n",
      "  monitor: Quantity to be monitored.\n",
      "  min_delta: Minimum change in the monitored quantity\n",
      "      to qualify as an improvement, i.e. an absolute\n",
      "      change of less than min_delta, will count as no\n",
      "      improvement.\n",
      "  patience: Number of epochs with no improvement\n",
      "      after which training will be stopped.\n",
      "  verbose: Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1\n",
      "      displays messages when the callback takes an action.\n",
      "  mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
      "      training will stop when the quantity\n",
      "      monitored has stopped decreasing; in `\"max\"`\n",
      "      mode it will stop when the quantity\n",
      "      monitored has stopped increasing; in `\"auto\"`\n",
      "      mode, the direction is automatically inferred\n",
      "      from the name of the monitored quantity.\n",
      "  baseline: Baseline value for the monitored quantity.\n",
      "      Training will stop if the model doesn't show improvement over the\n",
      "      baseline.\n",
      "  restore_best_weights: Whether to restore model weights from\n",
      "      the epoch with the best value of the monitored quantity.\n",
      "      If False, the model weights obtained at the last step of\n",
      "      training are used. An epoch will be restored regardless\n",
      "      of the performance relative to the `baseline`. If no epoch\n",
      "      improves on `baseline`, training will run for `patience`\n",
      "      epochs and restore weights from the best epoch in that set.\n",
      "\n",
      "Example:\n",
      "\n",
      ">>> callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
      ">>> # This callback will stop the training when there is no improvement in\n",
      ">>> # the loss for three consecutive epochs.\n",
      ">>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
      ">>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n",
      ">>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
      "...                     epochs=10, batch_size=1, callbacks=[callback],\n",
      "...                     verbose=0)\n",
      ">>> len(history.history['loss'])  # Only 4 epochs are run.\n",
      "4\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\mskyu\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "keras.callbacks.EarlyStopping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=500, verbose=1, validation_split=.2, callbacks=[es], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f7678e3cf7566e35dc0bd53f9a2e61d18c90ac4f700ab60c30179035bddd9e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
